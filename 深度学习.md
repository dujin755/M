# 深度学习  
## 1. 预备知识  
### 1.1 入门
导入 pytorch  
```python  
import torch
```  
使用 arrange 创建行向量  
```python 
x = torch.arange(12)
x
```  
通过张量的 shape 属性访问张量的形状  
```python
x.shape
```  
检查张量的总数  
```python
x.numel()
```  
有且只改变该张量的形状，不改变其中元素  
```python
X = x.reshape(3, 4)
X
```  
* 我们可以通过 **-1** 来调用此自动计算出维度的功能  
例子：用 `x.reshape(-1,4)` 或 `x.reshape(3,-1)` 来取代 `x.reshape(3,4)`  

设置 n 个 a 行 b 列的矩阵(其中元素全为 0)  
```python
torch.zeros((n,a,b))  
```  
全为 1 时 ：  
```python
torch.ones((n,a,b))
```  
从某个特定的概率分布中随机采样来得到张量中每个元素的值  
其中的每个元素都从均值为 0 、标准差为 1 的标准高斯分布（正态分布）中随机采样  
```python
torch.randn(a,b)
```  
### 1.2 运算符  
* 求幂运算  
```python
torch exp(x)
```  
* 也可以把多个张量连结（concatenate）在一起，把它们端对端地叠起来形成一个更大的张量  
```python
X = torch.arange(12, dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)
```  
```python
(tensor([[ 0., 1., 2., 3.],
[ 4., 5., 6., 7.],
[ 8., 9., 10., 11.],
[ 2., 1., 4., 3.],
[ 1., 2., 3., 4.],
[ 4., 3., 2., 1.]]),
tensor([[ 0., 1., 2., 3., 2., 1., 4., 3.],
[ 4., 5., 6., 7., 1., 2., 3., 4.],
[ 8., 9., 10., 11., 4., 3., 2., 1.]]))
```  
* 也可以进行逻辑运算符的运算  
* 对张量中所有元素求和  
```python
X.sum()
```  
### 1.3 广播机制  
该机制工作机制如下 ：  
* 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状  
* 对生成的数组执行按元素操作  
例子如下：  
```python
a = torch.arange(3).reshape((3, 1))
b = torch.arange(2).reshape((1, 2))
a, b
```  
```python
(tensor([[0],
         [1],
         [2]]),
tensor([[0, 1]]))
```  
当它们经行运算时，形状不匹配  
于是我们将两个矩阵广播为一个更大的 3 × 2 矩阵  
> 矩阵a将复制列  
矩阵b将复制行  
### 1.4 切片与索引  
与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是‐1  
可以指定范围以包含第一个元素和最后一个之前的元素  
还可以通过指定索引来将元素写入矩阵  
想为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值  
### 1.5 转化为其他Python对象  
将深度学习框架定义的张量转换为NumPy张量（ndarray）很容易，反之也同样容易  
```python
A = X.numpy()
B = torch.tensor(A)
type(A), type(B)
```
```python
(numpy.ndarray, torch.Tensor)
```  
要将大小为1的张量转换为Python标量，可以调用item函数或Python的内置函数  
```python
a = torch.tensor([3.5])
a, a.item(), float(a), int(a)
```  
```python
(tensor([3.5000]), 3.5, 3.5, 3)
```  
### 1.6 数据预处理  
使用pandas预处理原始数据，并将原始数据转换为张量格式的步骤  
#### 1.6.1 读取数据集  
例子 ：  
创建一个人工数据集，并存储在CSV（逗号分隔值）文件 ../data/house_tiny.csv 中  
下面将数据集按行写入CSV文件中 :
```python
import os
os.makedirs(os.path.join('..', 'data'), exist_ok=True)
data_file = os.path.join('..', 'data', 'house_tiny.csv')
with open(data_file, 'w') as f:
f.write('NumRooms,Alley,Price\n') # 列名
f.write('NA,Pave,127500\n') # 每行表示一个数据样本
f.write('2,NA,106000\n')
f.write('4,NA,178100\n')
f.write('NA,NA,140000\n')
```  
导入 pandas 包并调用 read_csv 函数 
```python 
import pandas as pd
data = pd.read_csv(data_file)
print(data)
```  
#### 1.6.2 处理缺失数据  
“NaN”项代表缺失值  
典型的方法包括插值法和删除法，插值法用一个替代值弥补缺失值，删除法则直接忽略缺失值  

通过位置索引 iloc ，将 data 分成 inputs 和 outputs ，其中前者为 data 的前两列，而后者为 data 的最后一列  
对于 inputs 中缺少的数值，用同一列的均值替换“NaN”项
```python
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
inputs = inputs.fillna(inputs.mean())
print(inputs)
```  
对于inputs中的类别值或离散值，将“NaN”视为一个类别 

由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”，pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”  

巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0  
缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1  
```python
inputs = pd.get_dummies(inputs, dummy_na=True)
print(inputs)
```  
#### 1.6.3 转化为张量格式  
```python
import torch
X = torch.tensor(inputs.to_numpy(dtype=float))
y = torch.tensor(outputs.to_numpy(dtype=float))
X, y
```  
### 1.7 线性代数  
#### 1.7.1 标量  
标量由只有一个元素的张量表示  
#### 1.7.2 向量  
向量可以被视为标量值组成的列表  
人们通过一维张量表示向量  
```python
x = torch.arange(4)
x
```  
```python  
tensor([0, 1, 2, 3])
```  
可以使用下标来引用向量的任一元素，例如可以通过xi来引用第i个元素  

向量的长度通常称为向量的维度（dimension）  
与普通的Python数组一样，我们可以通过调用Python的内置len()函数来访问张量的长度  
```python
len(x)
```  
当用张量表示一个向量（只有一个轴）时，我们也可以通过.shape属性访问向量的长度  
```python
x.shape
```  
**注意** ：维度（dimension）这个词在不同上下文时往往会有不同的含义  
* 向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量  
* 张量的维度用来表示张量具有的轴数  
#### 1.7.3 矩阵  
正如向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶  
当调用函数来实例化张量时，我们可以通过指定两个分量m和n来创建一个形状为m × n的矩阵  
```python
A = torch.arange(20).reshape(5, 4)
A
```  
现在在代码中访问矩阵的转置  
```python
A.T  
```  
#### 1.7.4 张量  
就像向量是标量的推广，矩阵是向量的推广一样，我们可以构建具有更多轴的数据结构  
张量是描述具有任意数量轴的n维数组的通用方法  

开始处理图像时，张量将变得更加重要，图像以n维数组形式出现，其中3个轴对应于高度、宽度，以及一个通道（channel）轴，用于表示颜色通道（红色、绿色和蓝色）  
#### 1.7.5 张量算法的基本形质  
将两个相同形状的矩阵相加，
会在这两个矩阵上执行元素加法  
```python
A = torch.arange(20, dtype=torch.float32).reshape(5, 4)
B = A.clone() # 通过分配新内存，将A的一个副本分配给B
A, A + B
```  
```python
(tensor([[ 0., 1., 2., 3.],
[ 4., 5., 6., 7.],
[ 8., 9., 10., 11.],
[12., 13., 14., 15.],
[16., 17., 18., 19.]]),
tensor([[ 0., 2., 4., 6.],
[ 8., 10., 12., 14.],
[16., 18., 20., 22.],
[24., 26., 28., 30.],
[32., 34., 36., 38.]]))
```  
两个矩阵的按元素乘法称为Hadamard积（Hadamard product）（数学符号⊙）  
```python
A * B 
```  
```python
tensor([[ 0., 1., 4., 9.],
[ 16., 25., 36., 49.],
[ 64., 81., 100., 121.],
[144., 169., 196., 225.],
[256., 289., 324., 361.]])
```  
* 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘  
#### 1.7.6 降维  
对任意张量进行的一个有用的操作是计算其元素的和  
```python  
x = torch.arange(4, dtype=torch.float32)
x, x.sum()
```  
可以表示任意形状张量的元素和  
```python
A.shape, A.sum()
```  
默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量  
还可以指定张量沿哪一个轴来通过求和降低维度  

以矩阵为例，为了通过求和所有行的元素来降维（轴0），可以在调用函数时指
定axis=0  
由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失  
```python
A_sum_axis0 = A.sum(axis=0)
A_sum_axis0, A_sum_axis0.shape
```  
指定axis=1将通过汇总所有列的元素降维（轴1）  
因此，输入轴1的维数在输出形状中消失  
```python
A_sum_axis1 = A.sum(axis=1)
A_sum_axis1, A_sum_axis1.shape
```  
* 沿着行和列对矩阵求和，等价于对矩阵的所有元素进行求和  
```python
A.sum(axis=[0, 1])
```  
*平均值*  
调用函数来计算任意形状张量的平均值  
```python
A.mean(), A.sum() / A.numel()
```  
计算平均值的函数也可以沿指定轴降低张量的维度  
```python
A.mean(axis=0), A.sum(axis=0) / A.shape[0]
```  
* **非降维求和**  
有时在调用函数来计算总和或均值时保持轴数不变会很有用  
```python
sum_A = A.sum(axis=1, keepdims=True)
sum_A
```  
```
tensor([[ 6.],
        [22.],
        [38.],
        [54.],
        [70.]])
```  
由于sum_A在对每行进行求和后仍保持两个轴，可以通过广播将A除以sum_A  
```python
A / sum_A
```  
想沿某个轴计算A元素的累积总和，比如axis=0（按行计算），可以调用cumsum函数  
此函数不会沿任何轴降低输入张量的维度  
```python
A.cumsum(axis=0)
```  
#### 1.7.7 点积  
```python
torch.ones(4, dtype = torch.float32)
x, y, torch.dot(x, y)
```  
可以通过执行按元素乘法，然后进行求和来表示两个向量的点积 ：  
```python
torch.sum(x * y)
```  
#### 1.7.8 矩阵-向量积  
在代码中使用张量表示矩阵‐向量积，使用mv函数  
当为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵‐向量积  

**注意** ： A的列维数（沿轴1的长度）必须与x的维数（其长度）相同  
```python  
A.shape, x.shape, torch.mv(A, x)
```  
#### 1.7.9 矩阵-矩阵乘法  
可以将矩阵‐矩阵乘法AB看作简单地执行m次矩阵‐向量积，并将结果拼接在一起，形成一个n × m矩阵  
```python
B = torch.ones(4, 3)
torch.mm(A, B)
```  
#### 1.7.10 范数  
非正式地说，向量的范数是表示一个向量有多大  
这里考虑的大小概念不涉及维度，而是分量的大小  

在线性代数中，向量范数是将向量映射到标量的函数f  
给定任意向量x，向量范数要满足一些属性  

* 第一个性质是：如果按常数因子α缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放 ： 
```math 
f(αx) = |α|f(x)
```  
* 第二个性质是熟悉的三角不等式 :  
```math  
f(x + y) ≤ f(x) + f(y)  
```  
* 第三个性质简单地说范数必须是非负的 :  
```math
f(x) ≥ 0
```  

事实上，欧几里得距离是一个L2范数：假设n维向量x中的元素是x1, . . . , xn，其L2范数是向量元素平方和的平方根  
在代码中，我们可以按如下方式计算向量的L2范数
```python  
u = torch.tensor([3.0, -4.0])
torch.norm(u)
```  
深度学习中更经常地使用L2范数的平方，也会经常遇到L1范数，它表示为向量元素的绝对值之和 ：  
```python
torch.abs(u).sum()
```  
### 1.8 微积分  
#### 1.8.1 导数与微分  
例子 ：定义u = f(x) 如下 ：  
```python  
%matplotlib inline
import numpy as np
from matplotlib_inline import backend_inline
from d2l import torch as d2l
def f(x):
return 3 * x ** 2 - 4 * x  
```  
```python
def numerical_lim(f, x, h):
return (f(x + h) - f(x)) / h
h = 0.1
for i in range(5):
print(f'h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')
h *= 0.1
```  
可得输出结果为 ：  
```python
h=0.10000, numerical limit=2.30000
h=0.01000, numerical limit=2.03000
h=0.00100, numerical limit=2.00300
h=0.00010, numerical limit=2.00030
h=0.00001, numerical limit=2.00003
```  
#### 1.8.2 偏导数  
#### 1.8.3 梯度  
函数f(x)相对于x的梯度是一个包含n个偏导数的向量  
#### 1.8.4 链式法则  
根据链式法则 ：  
```math
dy/dx =dy/du*du/dx
```  
### 1.9 自动微分  
```python
x.requires_grad_(True) # 等价于x=torch.arange(4.0,requires_grad=True)
x.grad # 默认值是None
```  
现在计算 y 值  
```python
y = 2 * torch.dot(x, x)
y
```  
x是一个长度为4的向量，计算x和x的点积，得到了我们赋值给y的标量输出  
接下来，通过调用反向传播函数来自动计算y关于x每个分量的梯度，并打印这些梯度  
```python
y.backward()
x.grad
```  
#### 1.9.1 非标量变量的反向传播  
当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵  
对于高阶和高维的y和x，求导的结果可以是一个高阶张量  

但当调用向量的反向计算时，通常会试图计算一批训练样本中每个组成部分的损失函数的导数  
目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和  
```python
# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。
# 本例只想求偏导数的和，所以传递一个1的梯度是合适的
x.grad.zero_()
y = x * x
# 等价于y.backward(torch.ones(len(x)))
y.sum().backward()
x.grad
```  
#### 1.9.2 分离计算  
如果希望将某些计算移动到记录的计算图之外  
想计算z关于x的梯度，但由于某种原因，希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用  

这里可以分离y来返回一个新变量u，该变量与y具有相同的值，但丢弃计算图中计算y任何信息  
因此，下面的反向传播函数计算z=u * x关于x的偏导数，同时将u作为常数处理，而不是z=x * x * x关于x的偏导数  
```python
x.grad.zero_()
y = x * x
u = y.detach()
z = u * x
z.sum().backward()
x.grad == u
```  
由于记录了y的计算结果，我们可以随后在y上调用反向传播，得到y=x * x关于的x的导数，即2 * x  
```python
x.grad.zero_()
y.sum().backward()
x.grad == 2 * x
```  
#### 1.9.3 Python控制流的梯度计算  
使用自动微分的一个好处是：即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度  
```python
def f(a):
b = a * 2
while b.norm() < 1000:
b = b * 2
if b.sum() > 0:
c = b
else:
c = 100 * b
return c
```  
计算梯度 ：  
```python  
a = torch.randn(size=(), requires_grad=True)
d = f(a)
d.backward()
```  

## 2. 线性神经网络  
### 2.1 线性回归  
回归（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法  
#### 2.1.1 线性回归的基本元素  
线性回归基于几个简单的假设：首先，假设自变量 **x** 和因变量 y 之间的关系是线性的，即 y 可以表示为 **x** 中元素的加权和，这里通常允许包含观测值的一些噪声；其次，我们假设任何噪声都比较正常，如噪声遵循正态分布  

**线性假设**  
以一个房屋的案例 ：  
线性假设是指目标（房屋价格）可以表示为特征（面积和房龄）的加权和，如下面的式子 ：  
```math
price = warea · area + wage · age + b.  
```  
warea和wage 称为权重（weight），权重决定了每个特征对我们预测值的影响  
b称为偏置（bias）、偏移量（offset）或截距（intercept）  
偏置是指当所有特征都取值为0时，预测值应该为多少  

给定一个数据集，我们的目标是寻找模型的权重 **w** 和偏置 b ，使得根据模型做出的预测大体符合数据里的真实价格  

而在机器学习领域，通常使用的是高维数据集，建模时采用线性代数表示法会比较方便。输入包含d个特征时，我们将预测结果yˆ （通常使用“尖角”符号表示y的估计值）表示为 :  
```math
yˆ = w1x1 + ... + wdxd + b.  
```  
将所有特征放到向量**x** ∈ Rd中，并将所有权重放到向量**w** ∈ Rd中，我们可以用点积形式来简洁地表达模型 ：  
```math
yˆ = w⊤x + b.
```  
**损失函数**  
开始考虑如何用模型拟合（fit）数据之前，需要确定一个拟合程度的度量  
损失函数（loss function）能够量化目标的实际值与预测值之间的差距  

通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0  
回归问题中最常用的损失函数是平方误差函数  
当样本i的预测值为yˆ(i)，其相应的真实标签为y(i)时，平方误差可以定义为以下公式 ：  
$$
l^i(w,b)={(\hat y^i -y^i)^2/2}
$$  
在训练模型时，我们希望寻找一组参数（w∗, b∗），这组参数能最小化在所有训练样本上的总损失  

**解析解**  
线性回归的解可以用一个公式简单地表达出来，这类解叫作解析解（analytical solution）  

***随机梯度下降***  
即便在无法得到解析解，仍然可以有效地训练模型  
用一种名为梯度下降（gradient descent）的方法，这种方法几乎可以优化所有深度学习模型  
梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值）关于模型参数的导数（在这里也可以称为梯度），但是这种方式在每一次更新参数时会遍历一遍数据库
因此，通常会在每次需要计算更新的时候随机抽取一小批样本，这种变体叫做小批量随机梯度下降  

算法的步骤如下：（1）初始化模型参数的值，如随机初始化；（2）从数据集中随机抽取小批量样
本且在负梯度的方向上更新参数，并不断迭代这一步骤  

在训练了预先确定的若干迭代次数后（或者直到满足某些其他停止条件后），记录下模型参数的估计值，表示为
$$\hat w ,\hat b$$  
但是即使函数确实是线性的且无噪声，这些估计值也不会使损失函数真正地达到最小值  
因为算法会使得损失向最小值缓慢收敛，但却不能在有限的步数内非常精确地达到最小值  
### 2.2 softmax 运算  
#### 2.2.1 网络架构  
为了估计所有可能类别的条件概率，需要一个有多个输出的模型，每个类别对应一个输出  
为了解决线性模型的分类问题，需要和输出一样多的仿射函数  

例子中，由于有4个特征和3个可能的输出类别   
将需要12个标量来表示权重  
3个标量来表示偏置 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <msub>
                <mi>o</mi>
                <mn>1</mn>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>11</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>12</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>13</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>14</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>b</mi>
                <mn>1</mn>
              </msub>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <msub>
                <mi>o</mi>
                <mn>2</mn>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>21</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>22</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>23</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>24</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>b</mi>
                <mn>2</mn>
              </msub>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <msub>
                <mi>o</mi>
                <mn>3</mn>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>31</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>32</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>33</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <msub>
                <mi>w</mi>
                <mrow data-mjx-texclass="ORD">
                  <mn>34</mn>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>b</mi>
                <mn>3</mn>
              </msub>
              <mo>.</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  
可以用神经网络图 图3.4.1来描述这个计算过程  
与线性回归一样，softmax回归也是一个单层神经网络 :  
![图像](https://zh.d2l.ai/_images/softmaxreg.svg)  
通过向量形式表达为<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">o</mi>
  </mrow>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">W</mi>
  </mrow>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo>+</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">b</mi>
  </mrow>
</math>这是一种更适合数学和编写代码的形式  
已经将所有权重放到一个3*4矩阵中  

#### 2.2.2 softmax 运算  
为了得到预测结果，将设置一个阈值，如选择具有最大概率的标签  
要将输出视为概率，必须保证在任何数据上的输出都是非负的且总和为1  
需要一个训练的目标函数，来激励模型精准地估计概率  

softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质  
为了完成这一目标，首先对每个未规范化的预测求幂，这样可以确保输出非负  
为了确保最终输出的概率值总和为1，再让每个求幂后的结果除以它们的总和，如下式 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mover>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">y</mi>
      </mrow>
      <mo stretchy="false">^</mo>
    </mover>
  </mrow>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi data-mjx-auto-op="false">softmax</mi>
  </mrow>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">o</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mstyle scriptlevel="0">
    <mspace width="1em"></mspace>
  </mstyle>
  <mtext>&#x5176;&#x4E2D;</mtext>
  <mstyle scriptlevel="0">
    <mspace width="1em"></mspace>
  </mstyle>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mover>
        <mi>y</mi>
        <mo stretchy="false">^</mo>
      </mover>
    </mrow>
    <mi>j</mi>
  </msub>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>o</mi>
        <mi>j</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <munder>
        <mo data-mjx-texclass="OP">&#x2211;</mo>
        <mi>k</mi>
      </munder>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>o</mi>
        <mi>k</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
  </mfrac>
</math>  

#### 2.2.3 损失函数  
需要一个损失函数来度量预测的效果  
将使用最大似然估计  
##### 2.2.3.1 对数似然  
softmax函数给出了一个向量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mover>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">y</mi>
      </mrow>
      <mo stretchy="false">^</mo>
    </mover>
  </mrow>
</math> 可以将其视为“对给定任意输入 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
</math> 的每个类的条件概率”  

可以将估计值与实际值进行比较 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">Y</mi>
  </mrow>
  <mo>&#x2223;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x220F;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>n</mi>
  </munderover>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">y</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mi>i</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2223;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">x</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mi>i</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>   
根据最大似然估计，最大化 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">Y</mi>
  </mrow>
  <mo>&#x2223;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <mo stretchy="false">)</mo>
</math> 相当于最小化负对数似然 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mo>&#x2212;</mo>
  <mi>log</mi>
  <mo data-mjx-texclass="NONE">&#x2061;</mo>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">Y</mi>
  </mrow>
  <mo>&#x2223;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>n</mi>
  </munderover>
  <mo>&#x2212;</mo>
  <mi>log</mi>
  <mo data-mjx-texclass="NONE">&#x2061;</mo>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">y</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mi>i</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2223;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">x</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mi>i</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>n</mi>
  </munderover>
  <mi>l</mi>
  <mo stretchy="false">(</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">y</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mi>i</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>,</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mover>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">y</mi>
        </mrow>
        <mo stretchy="false">^</mo>
      </mover>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mi>i</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo stretchy="false">)</mo>
  <mo>,</mo>
</math>  
其中，对于任何标签 **y** 和预测模型 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mover>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">y</mi>
      </mrow>
      <mo stretchy="false">^</mo>
    </mover>
  </mrow>
</math> 损失函数为 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>l</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">y</mi>
  </mrow>
  <mo>,</mo>
  <mrow data-mjx-texclass="ORD">
    <mover>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">y</mi>
      </mrow>
      <mo stretchy="false">^</mo>
    </mover>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mo>&#x2212;</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>j</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>q</mi>
  </munderover>
  <msub>
    <mi>y</mi>
    <mi>j</mi>
  </msub>
  <mi>log</mi>
  <mo data-mjx-texclass="NONE">&#x2061;</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mover>
        <mi>y</mi>
        <mo stretchy="false">^</mo>
      </mover>
    </mrow>
    <mi>j</mi>
  </msub>
  <mo>.</mo>
</math>  
该类损失函数通常被称为交叉熵损失函数  
##### 2.2.3.2 softmax 及其导数  
利用softmax的定义，我们得到 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <mi>l</mi>
              <mo stretchy="false">(</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">y</mi>
              </mrow>
              <mo>,</mo>
              <mrow data-mjx-texclass="ORD">
                <mover>
                  <mrow data-mjx-texclass="ORD">
                    <mi mathvariant="bold">y</mi>
                  </mrow>
                  <mo stretchy="false">^</mo>
                </mover>
              </mrow>
              <mo stretchy="false">)</mo>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mo>&#x2212;</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>j</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>q</mi>
              </munderover>
              <msub>
                <mi>y</mi>
                <mi>j</mi>
              </msub>
              <mi>log</mi>
              <mo data-mjx-texclass="NONE">&#x2061;</mo>
              <mfrac>
                <mrow>
                  <mi>exp</mi>
                  <mo data-mjx-texclass="NONE">&#x2061;</mo>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>o</mi>
                    <mi>j</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <munderover>
                    <mo data-mjx-texclass="OP">&#x2211;</mo>
                    <mrow data-mjx-texclass="ORD">
                      <mi>k</mi>
                      <mo>=</mo>
                      <mn>1</mn>
                    </mrow>
                    <mi>q</mi>
                  </munderover>
                  <mi>exp</mi>
                  <mo data-mjx-texclass="NONE">&#x2061;</mo>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>o</mi>
                    <mi>k</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </mtd>
          </mtr>
          <mtr>
            <mtd></mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>j</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>q</mi>
              </munderover>
              <msub>
                <mi>y</mi>
                <mi>j</mi>
              </msub>
              <mi>log</mi>
              <mo data-mjx-texclass="NONE">&#x2061;</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>k</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>q</mi>
              </munderover>
              <mi>exp</mi>
              <mo data-mjx-texclass="NONE">&#x2061;</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>o</mi>
                <mi>k</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>&#x2212;</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>j</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>q</mi>
              </munderover>
              <msub>
                <mi>y</mi>
                <mi>j</mi>
              </msub>
              <msub>
                <mi>o</mi>
                <mi>j</mi>
              </msub>
            </mtd>
          </mtr>
          <mtr>
            <mtd></mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mi>log</mi>
              <mo data-mjx-texclass="NONE">&#x2061;</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>k</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>q</mi>
              </munderover>
              <mi>exp</mi>
              <mo data-mjx-texclass="NONE">&#x2061;</mo>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>o</mi>
                <mi>k</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>&#x2212;</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>j</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>q</mi>
              </munderover>
              <msub>
                <mi>y</mi>
                <mi>j</mi>
              </msub>
              <msub>
                <mi>o</mi>
                <mi>j</mi>
              </msub>
              <mo>.</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  
考虑相对于任何未规范化的预测 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>o</mi>
    <mi>j</mi>
  </msub>
</math> 的导数，我们得到 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mi>&#x2202;</mi>
    <mrow data-mjx-texclass="ORD">
      <msub>
        <mi>o</mi>
        <mi>j</mi>
      </msub>
    </mrow>
  </msub>
  <mi>l</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">y</mi>
  </mrow>
  <mo>,</mo>
  <mrow data-mjx-texclass="ORD">
    <mover>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">y</mi>
      </mrow>
      <mo stretchy="false">^</mo>
    </mover>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>o</mi>
        <mi>j</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <munderover>
        <mo data-mjx-texclass="OP">&#x2211;</mo>
        <mrow data-mjx-texclass="ORD">
          <mi>k</mi>
          <mo>=</mo>
          <mn>1</mn>
        </mrow>
        <mi>q</mi>
      </munderover>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>o</mi>
        <mi>k</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
  </mfrac>
  <mo>&#x2212;</mo>
  <msub>
    <mi>y</mi>
    <mi>j</mi>
  </msub>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi data-mjx-auto-op="false">softmax</mi>
  </mrow>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">o</mi>
  </mrow>
  <msub>
    <mo stretchy="false">)</mo>
    <mi>j</mi>
  </msub>
  <mo>&#x2212;</mo>
  <msub>
    <mi>y</mi>
    <mi>j</mi>
  </msub>
  <mo>.</mo>
</math>  

##### 2.2.3.3 交叉熵损失  
现在用一个概率向量表示，如 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <mn>0.1</mn>
  <mo>,</mo>
  <mn>0.2</mn>
  <mo>,</mo>
  <mn>0.7</mn>
  <mo stretchy="false">)</mo>
</math> ，而不是仅包含二元项 (0,0,1) 的向量  
定义一个损失 *l* ,它是所有标签分布的预期损失值  
此损失被称为**交叉熵损失**，它是分类问题最常用的损失之一  

## 3. 多层感知机  
### 3.1 多层感知机  
#### 3.1.1 隐藏层  
在之前章节中描述了仿射变换，它是一种带偏置的线性变化  
该模型通过单个仿射变换将我们的输入直接映射到输出，然后进行softmax操作  
如果标签通过仿射变换后确实与输入数据相关，那么这种方法确实足够了  
但是仿射中的线性是一种很强的假设  
##### 3.1.1.1 线性变换的局限性  
线性意味着单调假设  
很容易找到违反单调性的假设 ：例如根据人的体温预测死亡率  
##### 3.1.1.2 在网络中加入隐藏层  
可以通过在网络中加入一个或多个隐藏层来克服线性模型的限制， 使其能处理更普遍的函数关系类型  
要做到这一点，最简单的方法是将许多全连接层堆叠在一起  
这种架构通常称为多层感知机，通常缩写为MLP  
![图片](https://zh.d2l.ai/_images/mlp.svg)  
注意，这两个层都是全连接的  
每个输入都会影响隐藏层中的每个神经元，而隐藏层中的每个神经元又会影响输出层中的每个神经元  
##### 3.1.1.3 从线性到非线性  
同之前的章节一样， 我们通过矩阵<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>n</mi>
      <mo>&#xD7;</mo>
      <mi>d</mi>
    </mrow>
  </msup>
</math>来表示 *n* 个样本的小批量，其中每个样本具有个输入 *d* 特征  
对于具有 *h* 个隐藏单元的单隐藏层多层感知机，用<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>n</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math>表示隐藏层的输出，称为隐藏表示  
因为隐藏层和输出层都是全连接的， 所以我们有隐藏层权重<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>d</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math> 和隐藏层偏置<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mn>1</mn>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math> 以及输出层权重<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mo>&#xD7;</mo>
      <mi>q</mi>
    </mrow>
  </msup>
</math> 和输出层偏置<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mn>1</mn>
      <mo>&#xD7;</mo>
      <mi>q</mi>
    </mrow>
  </msup>
</math>  
按如下方式计算单隐藏层多层感知机的输出 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">O</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>n</mi>
      <mo>&#xD7;</mo>
      <mi>q</mi>
    </mrow>
  </msup>
</math>  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">H</mi>
              </mrow>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">X</mi>
              </mrow>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">W</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>1</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">b</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>1</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">O</mi>
              </mrow>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">H</mi>
              </mrow>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">W</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>2</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">b</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>2</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo>.</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  
合并隐藏层，便可产生具有参数<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">W</mi>
  </mrow>
  <mo>=</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
</math> 和<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">b</mi>
  </mrow>
  <mo>=</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>+</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
</math> 的等价单层模型 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">O</mi>
  </mrow>
  <mo>=</mo>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>+</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo stretchy="false">)</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>+</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>+</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>+</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">W</mi>
  </mrow>
  <mo>+</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">b</mi>
  </mrow>
  <mo>.</mo>
</math>  
为了发挥多层架构的潜力，还需要一个额外的关键要素：在仿射变换之后对每个隐藏单元应用非线性的激活函数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3C3;</mi>
</math> 
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">H</mi>
              </mrow>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mi>&#x3C3;</mi>
              <mo stretchy="false">(</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">X</mi>
              </mrow>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">W</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>1</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">b</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>1</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo stretchy="false">)</mo>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">O</mi>
              </mrow>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">H</mi>
              </mrow>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">W</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>2</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">b</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mo stretchy="false">(</mo>
                  <mn>2</mn>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msup>
              <mo>.</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

#### 3.1.2 激活函数  
*激活函数* 通过计算加权和并加上偏置来确定神经元是否应该被激活，它们将输入信号转换为输出的可微运算  
##### 3.1.2.1 ReLU 函数  
最受欢迎的激活函数是修正线性单元  
因为它实现简单，同时在各种预测任务中表现良好  
给定元素 **x** ，ReLU函数被定义为该元素与的最大值 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>ReLU</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mo data-mjx-texclass="OP" movablelimits="true">max</mo>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo>,</mo>
  <mn>0</mn>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  
可见图像为 ：  

![图片](https://zh.d2l.ai/_images/output_mlp_76f463_18_1.svg)  
ReLU函数的导数图像 ：  

![图像](https://zh.d2l.ai/_images/output_mlp_76f463_33_1.svg)  
使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过  
并且ReLU减轻了困扰以往神经网络的梯度消失问题  
ReLU函数有许多变体，包括参数化ReLU函数   
该变体为ReLU添加了一个线性项，因此即使参数是负的，某些信息仍然可以通过 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>pReLU</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mo data-mjx-texclass="OP" movablelimits="true">max</mo>
  <mo stretchy="false">(</mo>
  <mn>0</mn>
  <mo>,</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>+</mo>
  <mi>&#x3B1;</mi>
  <mo data-mjx-texclass="OP" movablelimits="true">min</mo>
  <mo stretchy="false">(</mo>
  <mn>0</mn>
  <mo>,</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

##### 3.1.2.2 sigmoid 函数   
对于一个定义域在 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="double-struck">R</mi>
  </mrow>
</math> 中的输入， sigmoid函数将输入变换为区间(0, 1)上的输出  
sigmoid通常称为挤压函数  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>sigmoid</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mfrac>
    <mn>1</mn>
    <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <mo>&#x2212;</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </mfrac>
  <mo>.</mo>
</math>  

想要将输出视作二元分类问题的概率时， sigmoid仍然被广泛用作输出单元上的激活函数  
该函数图像为 ：  

![图片](https://zh.d2l.ai/_images/output_mlp_76f463_48_0.svg)  
igmoid函数的导数为下面的公式 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mi>d</mi>
    <mrow>
      <mi>d</mi>
      <mi>x</mi>
    </mrow>
  </mfrac>
  <mi>sigmoid</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <mo>&#x2212;</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo>+</mo>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <mo>&#x2212;</mo>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
      <msup>
        <mo stretchy="false">)</mo>
        <mn>2</mn>
      </msup>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mi>sigmoid</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mn>1</mn>
    <mo>&#x2212;</mo>
    <mi>sigmoid</mi>
    <mo stretchy="false">(</mo>
    <mi>x</mi>
    <mo stretchy="false">)</mo>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>.</mo>
</math>  

sigmoid函数的导数图像如下所示 ：  

![图片](https://zh.d2l.ai/_images/output_mlp_76f463_63_0.svg)  
这是会发现，当函数越是远离 0 点时，导数越接近 0 ， 该现象即使“梯度消失现象”  
##### 3.1.2.3 tanh 函数  
与sigmoid函数类似， tanh(双曲正切)函数也能将其输入压缩转换到区间(-1, 1)上

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>tanh</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mn>1</mn>
      <mo>&#x2212;</mo>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <mo>&#x2212;</mo>
      <mn>2</mn>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mn>1</mn>
      <mo>+</mo>
      <mi>exp</mi>
      <mo data-mjx-texclass="NONE">&#x2061;</mo>
      <mo stretchy="false">(</mo>
      <mo>&#x2212;</mo>
      <mn>2</mn>
      <mi>x</mi>
      <mo stretchy="false">)</mo>
    </mrow>
  </mfrac>
  <mo>.</mo>
</math>  
图像如下 ： 

![图片](https://zh.d2l.ai/_images/output_mlp_76f463_78_0.svg)  

tanh 的导数为  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mi>d</mi>
    <mrow>
      <mi>d</mi>
      <mi>x</mi>
    </mrow>
  </mfrac>
  <mi>tanh</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mn>1</mn>
  <mo>&#x2212;</mo>
  <msup>
    <mi>tanh</mi>
    <mn>2</mn>
  </msup>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

tanh函数的导数图像如下所示，与sigmoid 函数类似  

![图片](https://zh.d2l.ai/_images/output_mlp_76f463_93_0.svg)  

### 3.2 模型选择、欠拟合与过拟合  
#### 3.2.1 训练误差与泛化误差  
*训练误差* 是指， 模型在训练数据集上计算得到的误差  
*泛化误差* 是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望  
#### 3.2.2 模型选择  
通常在评估几个候选模型后选择最终的模型  
这个过程叫做模型选择  
##### 3.2.2.1 验证集  
常见的作法是将数据分成三份  
除了训练与测试以外  
还需要加一个验证数据集  
##### 3.2.2.2 K 折交叉验证  
当训练数据稀缺时，可能无法提供足够的数据来构成一个合适的验证集  
这个问题的一个流行的解决方案是采用 *K* 折交叉验证  

原始训练数据被分成 *K* 个不重叠的子集  
然后执行 *K* 次模型训练与验证  
每次在 *K - 1* 个子集上进行训练 ，在剩下那个子集上验证  
最后，对 *K* 次实验的结果取平均来训练和验证误差  
#### 3.2.3 欠拟合与过拟合  
模型过于简单，表达能力不足  
训练和验证误差之间的泛化误差很小 ，称为 *欠拟合*  

另一方面 ，训练误差明显低于验证误差 ，成为 *过拟合*  
##### 3.2.3.1 模型复杂度  
给定一个多项式的例子  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mover>
      <mi>y</mi>
      <mo stretchy="false">^</mo>
    </mover>
  </mrow>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mn>0</mn>
    </mrow>
    <mi>d</mi>
  </munderover>
  <msup>
    <mi>x</mi>
    <mi>i</mi>
  </msup>
  <msub>
    <mi>w</mi>
    <mi>i</mi>
  </msub>
</math>  

这只是一个线性回归问题，我们的特征是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>x</mi>
</math> 的幂给出的，模型的权重是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>w</mi>
    <mi>i</mi>
  </msub>
</math> 给出的，偏置是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>w</mi>
    <mn>0</mn>
  </msub>
</math>给出的  

下图直观给出多项式的阶数和欠拟合与过拟合之间的关系  

![图片](https://zh.d2l.ai/_images/capacity-vs-error.svg)  
### 3.3 权重衰减  
在训练参数化机器学习模型时，*权重衰减* 是最广泛使用的正则化的技术之一， 它通常也被称为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>L</mi>
    <mn>2</mn>
  </msub>
</math> 正则化  

一种简单的方法是通过线性函数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">w</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msup>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
</math> 中的权重向量的某个范数来度量其复杂性，例如 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <msup>
    <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
    <mn>2</mn>
  </msup>
</math>  
要保证权重向量比较小，最常用方法是将其范数作为惩罚项加到最小化损失的问题中  
如果权重向量增长太大，学习算法会集中最小化权重范数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <msup>
    <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
    <mn>2</mn>
  </msup>
</math>  
损失由下式给出 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>L</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <mo>,</mo>
  <mi>b</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mfrac>
    <mn>1</mn>
    <mi>n</mi>
  </mfrac>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>n</mi>
  </munderover>
  <mfrac>
    <mn>1</mn>
    <mn>2</mn>
  </mfrac>
  <msup>
    <mrow data-mjx-texclass="INNER">
      <mo data-mjx-texclass="OPEN">(</mo>
      <msup>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">w</mi>
        </mrow>
        <mi mathvariant="normal">&#x22A4;</mi>
      </msup>
      <msup>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mo stretchy="false">(</mo>
          <mi>i</mi>
          <mo stretchy="false">)</mo>
        </mrow>
      </msup>
      <mo>+</mo>
      <mi>b</mi>
      <mo>&#x2212;</mo>
      <msup>
        <mi>y</mi>
        <mrow data-mjx-texclass="ORD">
          <mo stretchy="false">(</mo>
          <mi>i</mi>
          <mo stretchy="false">)</mo>
        </mrow>
      </msup>
      <mo data-mjx-texclass="CLOSE">)</mo>
    </mrow>
    <mn>2</mn>
  </msup>
  <mo>.</mo>
</math>  
为了惩罚权重向量的大小，必须以某种方式在损失函数中添加 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <msup>
    <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
    <mn>2</mn>
  </msup>
</math>  

可以通过正则化常数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3BB;</mi>
</math>  来描述这种调整   
通过验证数据拟合 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>L</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <mo>,</mo>
  <mi>b</mi>
  <mo stretchy="false">)</mo>
  <mo>+</mo>
  <mfrac>
    <mi>&#x3BB;</mi>
    <mn>2</mn>
  </mfrac>
  <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <msup>
    <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
    <mn>2</mn>
  </msup>
  <mo>,</mo>
</math>  

* 对于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3BB;</mi>
  <mo>=</mo>
  <mn>0</mn>
</math>，我们恢复了原来的损失函数  
* 对于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3BB;</mi>
  <mo>&gt;</mo>
  <mn>0</mn>
</math>，我们限制 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
</math> 的大小  

<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>L</mi>
    <mn>2</mn>
  </msub>
</math> 正则化回归的小批量随机梯度下降更新如下式 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">w</mi>
        </mrow>
      </mtd>
      <mtd>
        <mi></mi>
        <mo stretchy="false">&#x2190;</mo>
        <mrow data-mjx-texclass="INNER">
          <mo data-mjx-texclass="OPEN">(</mo>
          <mn>1</mn>
          <mo>&#x2212;</mo>
          <mi>&#x3B7;</mi>
          <mi>&#x3BB;</mi>
          <mo data-mjx-texclass="CLOSE">)</mo>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">w</mi>
        </mrow>
        <mo>&#x2212;</mo>
        <mfrac>
          <mi>&#x3B7;</mi>
          <mrow>
            <mo stretchy="false">|</mo>
            <mrow data-mjx-texclass="ORD">
              <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>
            </mrow>
            <mo stretchy="false">|</mo>
          </mrow>
        </mfrac>
        <munder>
          <mo data-mjx-texclass="OP">&#x2211;</mo>
          <mrow data-mjx-texclass="ORD">
            <mi>i</mi>
            <mo>&#x2208;</mo>
            <mrow data-mjx-texclass="ORD">
              <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">B</mi>
            </mrow>
          </mrow>
        </munder>
        <msup>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">x</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mo stretchy="false">(</mo>
            <mi>i</mi>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
        <mrow data-mjx-texclass="INNER">
          <mo data-mjx-texclass="OPEN">(</mo>
          <msup>
            <mrow data-mjx-texclass="ORD">
              <mi mathvariant="bold">w</mi>
            </mrow>
            <mi mathvariant="normal">&#x22A4;</mi>
          </msup>
          <msup>
            <mrow data-mjx-texclass="ORD">
              <mi mathvariant="bold">x</mi>
            </mrow>
            <mrow data-mjx-texclass="ORD">
              <mo stretchy="false">(</mo>
              <mi>i</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </msup>
          <mo>+</mo>
          <mi>b</mi>
          <mo>&#x2212;</mo>
          <msup>
            <mi>y</mi>
            <mrow data-mjx-texclass="ORD">
              <mo stretchy="false">(</mo>
              <mi>i</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </msup>
          <mo data-mjx-texclass="CLOSE">)</mo>
        </mrow>
        <mo>.</mo>
      </mtd>
    </mtr>
  </mtable>
</math>  

### 3.4 暂退法  
#### 3.4.1 再看过拟合  
当面对更多的特征而样本不足时，线性模型往往会过拟合  
相反，当给出更多样本而不是特征，通常线性模型不会过拟合  

但是线性模型没有考虑特征之间的交互作用，对于每个特征线性模型都必须指定正的或负的权重，从而忽略了其它特征  

泛化性和灵活性之间的这种基本权衡被描述为 *偏差-方差权衡*  
> 线性模型有很高的偏差：它们只能表示一小类函数  
模型的方差很低：它们在不同的随机数据样本上可以得出相似的结果  
#### 3.4.2 扰动的稳定性  
经典泛化理论认为，为了缩小训练和测试性能之间的差距，应该以简单的模型为目标  

在训练过程中，在计算后续层之前向网络的每一层注入噪声  
因为当训练一个有多层的深层网络时，注入噪声只会在输入-输出映射上增强平滑性  

这个想法被称为 *暂退法*  
暂退法在前向传播过程中，计算每一内部层的同时注入噪声，这已经成为训练神经网络的常用技术  
该种方法之所以被称为暂退法  
是因为从表面上看在训练过程中会丢弃一些神经元  

那么关键的挑战就是如何注入这种噪声  
在毕晓普的工作中，他将高斯噪声添加到线性模型的输入中  
在每次训练迭代中，他将从均值为零的分布 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3F5;</mi>
  <mo>&#x223C;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi data-mjx-variant="-tex-calligraphic" mathvariant="script">N</mi>
  </mrow>
  <mo stretchy="false">(</mo>
  <mn>0</mn>
  <mo>,</mo>
  <msup>
    <mi>&#x3C3;</mi>
    <mn>2</mn>
  </msup>
  <mo stretchy="false">)</mo>
</math>采样噪声添加到输入 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
</math>， 从而产生扰动点<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">x</mi>
    </mrow>
    <mo data-mjx-alternate="1">&#x2032;</mo>
  </msup>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo>+</mo>
  <mi>&#x3F5;</mi>
</math> ， 预期是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>E</mi>
  <mo stretchy="false">[</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">x</mi>
    </mrow>
    <mo data-mjx-alternate="1">&#x2032;</mo>
  </msup>
  <mo stretchy="false">]</mo>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
</math>  
在标准暂退法正则化中，通过按保留（未丢弃）的节点的分数进行规范化来消除每一层的偏差  
每个中间活性值 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>h</mi>
</math> 以暂退概率 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>p</mi>
</math> 由随机变量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mi>h</mi>
    <mo data-mjx-alternate="1">&#x2032;</mo>
  </msup>
</math> 替换  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnspacing="" rowspacing="3pt">
          <mtr>
            <mtd>
              <msup>
                <mi>h</mi>
                <mo data-mjx-alternate="1">&#x2032;</mo>
              </msup>
              <mo>=</mo>
              <mrow data-mjx-texclass="INNER">
                <mo data-mjx-texclass="OPEN">{</mo>
                <mtable columnalign="left left" columnspacing="1em" rowspacing=".2em">
                  <mtr>
                    <mtd>
                      <mn>0</mn>
                    </mtd>
                    <mtd>
                      <mtext>&#xA0;&#x6982;&#x7387;&#x4E3A;&#xA0;</mtext>
                      <mi>p</mi>
                    </mtd>
                  </mtr>
                  <mtr>
                    <mtd>
                      <mfrac>
                        <mi>h</mi>
                        <mrow>
                          <mn>1</mn>
                          <mo>&#x2212;</mo>
                          <mi>p</mi>
                        </mrow>
                      </mfrac>
                    </mtd>
                    <mtd>
                      <mtext>&#xA0;&#x5176;&#x4ED6;&#x60C5;&#x51B5;</mtext>
                    </mtd>
                  </mtr>
                </mtable>
                <mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo>
              </mrow>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

#### 3.4.3 实践中的暂退法  
将暂退法应用到隐藏层，以 *p* 的概率将隐藏单元置为零时，结果可以看作一个只包含原始神经元子集的网络    
就如图所示 ：  
![图片](https://zh.d2l.ai/_images/dropout2.svg)  

### 3.5 正向传播、反向传播和计算图  
#### 3.5.1 正向传播  
**前向传播** 指的是：按顺序（从输入层到输出层）计算和存储神经网络中每层的结果  
假设输入样本是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>d</mi>
  </msup>
</math> ， 并且我们的隐藏层不包括偏置项  
即中间变量为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">z</mi>
  </mrow>
  <mo>=</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo>,</mo>
</math>  

其中 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mo>&#xD7;</mo>
      <mi>d</mi>
    </mrow>
  </msup>
</math>是隐藏层的权重参数  
将中间变量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">z</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>h</mi>
  </msup>
</math> 通过激活函数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3D5;</mi>
</math> 后， 我们得到长度为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>h</mi>
</math> 的隐藏激活向量 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">h</mi>
  </mrow>
  <mo>=</mo>
  <mi>&#x3D5;</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">z</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

隐藏变量 **h** 也是一个中间变量。假设输出层的参数只有权重 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math> ， 我们可以得到输出层变量，它是一个长度为 q 的向量 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">o</mi>
  </mrow>
  <mo>=</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">h</mi>
  </mrow>
  <mo>.</mo>
</math>  

假设损失函数为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>l</mi>
</math> ，样本标签为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>y</mi>
</math> ，我们可以计算单个数据样本的损失项， 

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>L</mi>
  <mo>=</mo>
  <mi>l</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">o</mi>
  </mrow>
  <mo>,</mo>
  <mi>y</mi>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

根据 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>L</mi>
    <mn>2</mn>
  </msub>
</math> 正则化的定义，给定超参数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>L</mi>
    <mn>2</mn>
  </msub>
</math> ，正则化项为  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>s</mi>
  <mo>=</mo>
  <mfrac>
    <mi>&#x3BB;</mi>
    <mn>2</mn>
  </mfrac>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
    <msup>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">W</mi>
      </mrow>
      <mrow data-mjx-texclass="ORD">
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
      </mrow>
    </msup>
    <msubsup>
      <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
      <mi>F</mi>
      <mn>2</mn>
    </msubsup>
    <mo>+</mo>
    <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
    <msup>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">W</mi>
      </mrow>
      <mrow data-mjx-texclass="ORD">
        <mo stretchy="false">(</mo>
        <mn>2</mn>
        <mo stretchy="false">)</mo>
      </mrow>
    </msup>
    <msubsup>
      <mo data-mjx-texclass="ORD" fence="false" stretchy="false">&#x2016;</mo>
      <mi>F</mi>
      <mn>2</mn>
    </msubsup>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>,</mo>
</math>  

最后，模型在给定数据样本上的正则化损失为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>J</mi>
  <mo>=</mo>
  <mi>L</mi>
  <mo>+</mo>
  <mi>s</mi>
  <mo>.</mo>
</math>  

在下面的讨论中，我们 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>J</mi>
</math> 将称为目标函数  

#### 3.5.2 正向传播计算图  
![图片](https://zh.d2l.ai/_images/forward.svg)  

#### 3.5.3 反向传播  
反向传播指的是计算神经网络参数梯度的方法  
该方法根据微积分中的链式规则，按相反的顺序从输出层到输入层遍历网络  

假设我们有函数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">Y</mi>
  </mrow>
  <mo>=</mo>
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">X</mi>
  </mrow>
  <mo stretchy="false">)</mo>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">Z</mi>
  </mrow>
  <mo>=</mo>
  <mi>g</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">Y</mi>
  </mrow>
  <mo stretchy="false">)</mo>
</math> ， 其中输入和输出 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">X</mi>
  </mrow>
  <mo>,</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">Y</mi>
  </mrow>
  <mo>,</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">Z</mi>
  </mrow>
</math> 是任意形状的张量  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="sans-serif">Z</mi>
      </mrow>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="sans-serif">X</mi>
      </mrow>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="sans-serif">Z</mi>
        </mrow>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="sans-serif">Y</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="sans-serif">Y</mi>
        </mrow>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="sans-serif">X</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>.</mo>
</math>  


计算顺序与正向传播中执行的顺序相反，因为要从计算图的结果开始，并朝着参数的方向努力  
第一步是计算目标函数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>J</mi>
  <mo>=</mo>
  <mi>L</mi>
  <mo>+</mo>
  <mi>s</mi>
</math> 相对于损失项 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>L</mi>
</math> 和正则项 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>s</mi>
</math> 的梯度  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mn>1</mn>
  <mstyle scriptlevel="0">
    <mspace width="0.278em"></mspace>
  </mstyle>
  <mtext>and</mtext>
  <mstyle scriptlevel="0">
    <mspace width="0.278em"></mspace>
  </mstyle>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>s</mi>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mn>1.</mn>
</math>  

接下来，根据链式法则计算目标函数关于输出层变量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">o</mi>
  </mrow>
</math> 的梯度 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">o</mi>
      </mrow>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>J</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>L</mi>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>L</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">o</mi>
      </mrow>
    </mrow>
  </mfrac>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>q</mi>
  </msup>
  <mo>.</mo>
</math>  

接下来，计算正则化项相对于两个参数的梯度 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>s</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msup>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">W</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mo stretchy="false">(</mo>
          <mn>1</mn>
          <mo stretchy="false">)</mo>
        </mrow>
      </msup>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mi>&#x3BB;</mi>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mstyle scriptlevel="0">
    <mspace width="0.278em"></mspace>
  </mstyle>
  <mtext>and</mtext>
  <mstyle scriptlevel="0">
    <mspace width="0.278em"></mspace>
  </mstyle>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>s</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msup>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">W</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mo stretchy="false">(</mo>
          <mn>2</mn>
          <mo stretchy="false">)</mo>
        </mrow>
      </msup>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mi>&#x3BB;</mi>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>.</mo>
</math>  

可以计算最接近输出层的模型参数的梯度 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <mi>J</mi>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math>

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msup>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">W</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mo stretchy="false">(</mo>
          <mn>2</mn>
          <mo stretchy="false">)</mo>
        </mrow>
      </msup>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>J</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msup>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">W</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mo stretchy="false">(</mo>
            <mn>2</mn>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>+</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>J</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>s</mi>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>s</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msup>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">W</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mo stretchy="false">(</mo>
            <mn>2</mn>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">o</mi>
      </mrow>
    </mrow>
  </mfrac>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">h</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msup>
  <mo>+</mo>
  <mi>&#x3BB;</mi>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>2</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>.</mo>
</math>  

为了获得关于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
</math> 的梯度，需要继续沿着输出层到隐藏层反向传播  
关于隐藏层输出的梯度 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <mi>J</mi>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">h</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>h</mi>
  </msup>
</math> 由下式给出 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">h</mi>
      </mrow>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>J</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">h</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>=</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <msup>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">W</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mo stretchy="false">(</mo>
          <mn>2</mn>
          <mo stretchy="false">)</mo>
        </mrow>
      </msup>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msup>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">o</mi>
      </mrow>
    </mrow>
  </mfrac>
  <mo>.</mo>
</math>  

由于激活函数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3D5;</mi>
</math> 是按元素计算的，计算中间 **z** 变量的梯度 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <mi>J</mi>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">z</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>h</mi>
  </msup>
</math> 需要使用按元素乘法运算符，我们用 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo>&#x2299;</mo>
</math> 表示 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">z</mi>
      </mrow>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>J</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">h</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">h</mi>
        </mrow>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">z</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">h</mi>
      </mrow>
    </mrow>
  </mfrac>
  <mo>&#x2299;</mo>
  <msup>
    <mi>&#x3D5;</mi>
    <mo data-mjx-alternate="1">&#x2032;</mo>
  </msup>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">z</mi>
    </mrow>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>.</mo>
</math>   

最后，可以得到最接近输入层的模型参数的梯度 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <mi>J</mi>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mo>&#xD7;</mo>
      <mi>d</mi>
    </mrow>
  </msup>
</math> ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msup>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">W</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mo stretchy="false">(</mo>
          <mn>1</mn>
          <mo stretchy="false">)</mo>
        </mrow>
      </msup>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>J</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">z</mi>
        </mrow>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">z</mi>
        </mrow>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msup>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">W</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mo stretchy="false">(</mo>
            <mn>1</mn>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>+</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>J</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>s</mi>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>s</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msup>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">W</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mo stretchy="false">(</mo>
            <mn>1</mn>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>J</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <mrow data-mjx-texclass="ORD">
        <mi mathvariant="bold">z</mi>
      </mrow>
    </mrow>
  </mfrac>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">x</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msup>
  <mo>+</mo>
  <mi>&#x3BB;</mi>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mo stretchy="false">(</mo>
      <mn>1</mn>
      <mo stretchy="false">)</mo>
    </mrow>
  </msup>
  <mo>.</mo>
</math>  

#### 3.5.4 训练神经网络  
在训练神经网络时，正向传播和反向传播相互依赖  

### 3.6 数值稳定性和模型初始化  
#### 3.6.1 梯度消失与梯度爆炸  
不稳定梯度带来的风险不止在于数值表示；不稳定梯度也威胁到优化算法的稳定性  

* **梯度爆炸**问题 ：参数更新过大，破坏了模型的稳定收敛  
* **梯度消失**问题： 参数更新过小，在每次更新时几乎不会移动，导致模型无法学习  

##### 3.6.1.1 梯度消失  
之前提过的 sigmoid 函数就存在这种问题  
![图片](https://zh.d2l.ai/_images/output_numerical-stability-and-init_e60514_6_0.svg)  
正如上图，当sigmoid函数的输入很大或是很小时，它的梯度都会消失  

##### 3.6.1.2 梯度爆炸  
为了更好地说明这一点，生成100个高斯随机矩阵，并将它们与某个初始矩阵相乘  
对于我们选择的尺度（方差 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mi>&#x3C3;</mi>
    <mn>2</mn>
  </msup>
  <mo>=</mo>
  <mn>1</mn>
</math> ），矩阵乘积发生爆炸  

```python 
一个矩阵
 tensor([[-0.7872,  2.7090,  0.5996, -1.3191],
        [-1.8260, -0.7130, -0.5521,  0.1051],
        [ 1.1213,  1.0472, -0.3991, -0.3802],
        [ 0.5552,  0.4517, -0.3218,  0.5214]])
乘以100个矩阵后
 tensor([[-2.1897e+26,  8.8308e+26,  1.9813e+26,  1.7019e+26],
        [ 1.3110e+26, -5.2870e+26, -1.1862e+26, -1.0189e+26],
        [-1.6008e+26,  6.4559e+26,  1.4485e+26,  1.2442e+26],
        [ 3.0943e+25, -1.2479e+26, -2.7998e+25, -2.4050e+25]])
```  

#### 3.6.2 参数初始化  
##### 3.6.2.1 默认初始化  
##### 3.6.2.2 Xavier 初始化  
满足 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="" rowspacing="3pt">
    <mtr>
      <mtd>
        <mfrac>
          <mn>1</mn>
          <mn>2</mn>
        </mfrac>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>n</mi>
          <mrow data-mjx-texclass="ORD">
            <mi data-mjx-auto-op="false">in</mi>
          </mrow>
        </msub>
        <mo>+</mo>
        <msub>
          <mi>n</mi>
          <mrow data-mjx-texclass="ORD">
            <mi data-mjx-auto-op="false">out</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <msup>
          <mi>&#x3C3;</mi>
          <mn>2</mn>
        </msup>
        <mo>=</mo>
        <mn>1</mn>
        <mtext>&#xA0;&#x6216;&#x7B49;&#x4EF7;&#x4E8E;&#xA0;</mtext>
        <mi>&#x3C3;</mi>
        <mo>=</mo>
        <msqrt>
          <mfrac>
            <mn>2</mn>
            <mrow>
              <msub>
                <mi>n</mi>
                <mrow data-mjx-texclass="ORD">
                  <mi data-mjx-auto-op="false">in</mi>
                </mrow>
              </msub>
              <mo>+</mo>
              <msub>
                <mi>n</mi>
                <mrow data-mjx-texclass="ORD">
                  <mi data-mjx-auto-op="false">out</mi>
                </mrow>
              </msub>
            </mrow>
          </mfrac>
        </msqrt>
        <mo>.</mo>
      </mtd>
    </mtr>
  </mtable>
</math>  
这就是现在标准且实用的Xavier初始化的基础  
通常，Xavier初始化从均值为零，方差 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mi>&#x3C3;</mi>
    <mn>2</mn>
  </msup>
  <mo>=</mo>
  <mfrac>
    <mn>2</mn>
    <mrow>
      <msub>
        <mi>n</mi>
        <mrow data-mjx-texclass="ORD">
          <mi data-mjx-auto-op="false">in</mi>
        </mrow>
      </msub>
      <mo>+</mo>
      <msub>
        <mi>n</mi>
        <mrow data-mjx-texclass="ORD">
          <mi data-mjx-auto-op="false">out</mi>
        </mrow>
      </msub>
    </mrow>
  </mfrac>
</math> 的高斯分布中采样权重  

## 4. 深度学习计算  
### 4.1 层和块  
单个神经网络  

* 接受一些输入  
* 生成相应的标量输出   
* 具有一组相关参数 ，更新这些参数可以优化某目标函数  

当考虑具有多个输出的网络时，利用矢量化算法来描述整层神经元  

* 接受一组输入  
* 生成相应的输出  
* 由一组可调整参数描述  

![图片](https://zh.d2l.ai/_images/blocks.svg)  

#### 4.1.1 自定义块  
```python  
class MLP(nn.Module):
    # 用模型参数声明层。这里，我们声明两个全连接的层
    def __init__(self):
        # 调用MLP的父类Module的构造函数来执行必要的初始化。
        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）
        super().__init__()
        self.hidden = nn.Linear(20, 256)  # 隐藏层
        self.out = nn.Linear(256, 10)  # 输出层

    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出
    def forward(self, X):
        # 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。
        return self.out(F.relu(self.hidden(X)))  
```  
可以试一下这个函数 ：  
```python
net = MLP()
net(x)
```  
```python
tensor([[ 0.0669,  0.2202, -0.0912, -0.0064,  0.1474, -0.0577, -0.3006,  0.1256,
         -0.0280,  0.4040],
        [ 0.0545,  0.2591, -0.0297,  0.1141,  0.1887,  0.0094, -0.2686,  0.0732,
         -0.0135,  0.3865]], grad_fn=<AddmmBackward0>)
```  

块的一个主要优点是它的多功能性  
可以子类化块以创建层（如全连接层的类）、 整个模型（如上面的MLP类）或具有中等复杂度的各种组件  

#### 4.1.2 顺序块  
只需要定义两个关键函数 ：  

> 一种将块逐个追加到列表中的函数  
一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”  

```python
class MySequential(nn.Module):
    def __init__(self, *args):
        super().__init__()
        for idx, module in enumerate(args):
            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员
            # 变量_modules中。_module的类型是OrderedDict
            self._modules[str(idx)] = module

    def forward(self, X):
        # OrderedDict保证了按照成员添加的顺序遍历它们
        for block in self._modules.values():
            X = block(X)
        return X
```  

__init__函数将每个模块逐个添加到有序字典_modules中  
_modules的主要优点是：在模块的参数初始化过程中，系统知道在_modules字典中查找需要初始化参数的子块  

当MySequential的前向传播函数被调用时， 每个添加的块都按照它们被添加的顺序执行  

```python
net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))
net(X)
```  
```python  
tensor([[ 2.2759e-01, -4.7003e-02,  4.2846e-01, -1.2546e-01,  1.5296e-01,
          1.8972e-01,  9.7048e-02,  4.5479e-04, -3.7986e-02,  6.4842e-02],
        [ 2.7825e-01, -9.7517e-02,  4.8541e-01, -2.4519e-01, -8.4580e-02,
          2.8538e-01,  3.6861e-02,  2.9411e-02, -1.0612e-01,  1.2620e-01]],
       grad_fn=<AddmmBackward0>)
```  

#### 4.1.3 在正向传播函数中执行代码  
需要一个计算函数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo>,</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mi>c</mi>
  <mo>&#x22C5;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">w</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msup>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
</math> 的层， 其中 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
</math> 是输入， <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">w</mi>
  </mrow>
</math> 是参数， <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>c</mi>
</math> 是某个在优化过程中没有更新的指定常量时   
因此实现了一个FixedHiddenMLP类 ：  
```python
class FixedHiddenMLP(nn.Module):
    def __init__(self):
        super().__init__()
        # 不计算梯度的随机权重参数。因此其在训练期间保持不变
        self.rand_weight = torch.rand((20, 20), requires_grad=False)
        self.linear = nn.Linear(20, 20)

    def forward(self, X):
        X = self.linear(X)
        # 使用创建的常量参数以及relu和mm函数
        X = F.relu(torch.mm(X, self.rand_weight) + 1)
        # 复用全连接层。这相当于两个全连接层共享参数
        X = self.linear(X)
        # 控制流
        while X.abs().sum() > 1:
            X /= 2
        return X.sum()
```  

在FixedHiddenMLP模型中，实现了一个隐藏层，其权重在实例化时被随机初始化，之后为常量  
这个权重不是一个模型参数，因此它永远不会被反向传播更新  
然后，神经网络将这个固定层的输出通过一个全连接层  
```python
net = FixedHiddenMLP()
net(X)
```  

```python 
tensor(0.1862, grad_fn=<SumBackward0>)  
```  

### 4.2 参数管理  
本节，我们将介绍以下内容 ：  

* 访问参数，用于调试、诊断和可视化  
* 参数初始化  
* 在不同模型组件间共享参数  

#### 4.2.1 参数访问  
首先，这个全连接层包含两个参数，分别是该层的权重和偏置  
两者都储存单精度浮点数  
**注意** ： 参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此  
##### 4.2.1.1 目标参数  
每个参数都表示为参数类的一个实例  
要对参数执行任何操作，首先我们需要访问底层的数值  
下面的代码从第二个全连接层（即第三个神经网络层）提取偏置，提取后返回的是一个参数类实例，并进一步访问该参数的值  
```python
print(type(net[1].bias))
print(net[1].bias)
print(net[1].bias.data()) 
```  

参数是复合的对象，包含值、梯度和额外信息  
这就是我们需要显式参数值的原因  
除了值之外，我们还可以访问每个参数的梯度  
##### 4.2.1.2 一次性访问所有参数  
需要对所有参数执行操作时，逐个访问它们可能会很麻烦  
处理更复杂的块（例如，嵌套块）时，情况可能会变得特别复杂， 因为我们需要递归整个树来提取每个子块的参数  
下面，通过演示来比较访问第一个全连接层的参数和访问所有层 ：  
```python
print(*[(name, param.shape) for name, param in net[0].named_parameters()])
print(*[(name, param.shape) for name, param in net.named_parameters()])

```  
```python
('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))
('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))
```  

##### 4.2.1.3 从嵌套块收集参数  
定义一个生成块的函数（可以说是“块工厂”），然后将这些块组合到更大的块中  
```python
def block1():
    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),
                         nn.Linear(8, 4), nn.ReLU())

def block2():
    net = nn.Sequential()
    for i in range(4):
        # 在这里嵌套
        net.add_module(f'block {i}', block1())
    return net

rgnet = nn.Sequential(block2(), nn.Linear(4, 1))
rgnet(X)

```
```python
tensor([[0.2596],
        [0.2596]], grad_fn=<AddmmBackward0>)
```  
#### 4.2.2 参数初始化  
##### 4.2.2.1 内置初始化  
首先调用内置的初始化器  
```python
def init_normal(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, mean=0, std=0.01)
        nn.init.zeros_(m.bias)
net.apply(init_normal)
net[0].weight.data[0], net[0].bias.data[0]
``` 
##### 4.2.2.2 自定义初始化  
在下面的例子中，我们使用以下的分布为任意权重参数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>w</mi>
</math> 定义初始化方法 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnspacing="" rowspacing="3pt">
          <mtr>
            <mtd>
              <mi>w</mi>
              <mo>&#x223C;</mo>
              <mrow data-mjx-texclass="INNER">
                <mo data-mjx-texclass="OPEN">{</mo>
                <mtable columnalign="left left" columnspacing="1em" rowspacing=".2em">
                  <mtr>
                    <mtd>
                      <mi>U</mi>
                      <mo stretchy="false">(</mo>
                      <mn>5</mn>
                      <mo>,</mo>
                      <mn>10</mn>
                      <mo stretchy="false">)</mo>
                    </mtd>
                    <mtd>
                      <mtext>&#xA0;&#x53EF;&#x80FD;&#x6027;&#xA0;</mtext>
                      <mfrac>
                        <mn>1</mn>
                        <mn>4</mn>
                      </mfrac>
                    </mtd>
                  </mtr>
                  <mtr>
                    <mtd>
                      <mn>0</mn>
                    </mtd>
                    <mtd>
                      <mtext>&#xA0;&#x53EF;&#x80FD;&#x6027;&#xA0;</mtext>
                      <mfrac>
                        <mn>1</mn>
                        <mn>2</mn>
                      </mfrac>
                    </mtd>
                  </mtr>
                  <mtr>
                    <mtd>
                      <mi>U</mi>
                      <mo stretchy="false">(</mo>
                      <mo>&#x2212;</mo>
                      <mn>10</mn>
                      <mo>,</mo>
                      <mo>&#x2212;</mo>
                      <mn>5</mn>
                      <mo stretchy="false">)</mo>
                    </mtd>
                    <mtd>
                      <mtext>&#xA0;&#x53EF;&#x80FD;&#x6027;&#xA0;</mtext>
                      <mfrac>
                        <mn>1</mn>
                        <mn>4</mn>
                      </mfrac>
                    </mtd>
                  </mtr>
                </mtable>
                <mo data-mjx-texclass="CLOSE" fence="true" stretchy="true" symmetric="true"></mo>
              </mrow>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

实现了一个my_init函数来应用到net  
```python
def my_init(m):
    if type(m) == nn.Linear:
        print("Init", *[(name, param.shape)
                        for name, param in m.named_parameters()][0])
        nn.init.uniform_(m.weight, -10, 10)
        m.weight.data *= m.weight.data.abs() >= 5

net.apply(my_init)
net[0].weight[:2]
```  
```python
Init weight torch.Size([8, 4])
Init weight torch.Size([1, 8])
```  
#### 4.2.3 参数绑定  
希望在多个层间共享参数：可以定义一个稠密层，然后使用它的参数来设置另一个层的参数  
```python
# 我们需要给共享层一个名称，以便可以引用它的参数
shared = nn.Linear(8, 8)
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),
                    shared, nn.ReLU(),
                    shared, nn.ReLU(),
                    nn.Linear(8, 1))
net(X)
# 检查参数是否相同
print(net[2].weight.data[0] == net[4].weight.data[0])
net[2].weight.data[0, 0] = 100
# 确保它们实际上是同一个对象，而不只是有相同的值
print(net[2].weight.data[0] == net[4].weight.data[0])
```  
### 4.3 延后初始化  
### 4.4 自定义层  
通过自定义层增加神经网络的灵活性  
#### 4.4.1 不带参数的层  
构造一个没有任何参数的自定义层  
要构建它，我们只需继承基础层类并实现前向传播功能  
```python
import torch
import torch.nn.functional as F
from torch import nn


class CenteredLayer(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, X):
        return X - X.mean()
```  
#### 4.4.2 带参数的层  
可以使用内置函数来创建参数，这些函数提供一些基本的管理功能  
```python
class MyLinear(nn.Module):
    def __init__(self, in_units, units):
        super().__init__()
        self.weight = nn.Parameter(torch.randn(in_units, units))
        self.bias = nn.Parameter(torch.randn(units,))
    def forward(self, X):
        linear = torch.matmul(X, self.weight.data) + self.bias.data
        return F.relu(linear)
```  
### 4.5 读写文件  
#### 4.5.1 加载与保存张量  
对于单个张量，可以直接调用load和save函数分别读写它们  
这两个函数都要求我们提供一个名称，save要求将要保存的变量作为输入 ：  
```python
import torch
from torch import nn
from torch.nn import functional as F

x = torch.arange(4)
torch.save(x, 'x-file')
```  
现在可以将存储在文件中的数据读回内存  
```python
x2 = torch.load('x-file')
x2
```  
可以存储一个张量列表，然后把它们读回内存  
```python  
y = torch.zeros(4)
torch.save([x, y],'x-files')
x2, y2 = torch.load('x-files')
(x2, y2)
```  
可以写入或读取从字符串映射到张量的字典  
```python  
mydict = {'x': x, 'y': y}
torch.save(mydict, 'mydict')
mydict2 = torch.load('mydict')
mydict2
```  
#### 4.5.2 加载与保存模型参数  
```python  
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.hidden = nn.Linear(20, 256)
        self.output = nn.Linear(256, 10)

    def forward(self, x):
        return self.output(F.relu(self.hidden(x)))

net = MLP()
X = torch.randn(size=(2, 20))
Y = net(X)
```  
将模型的参数存储在一个叫做“mlp.params”的文件中  
```python
torch.save(net.state_dict(), 'mlp.params')
```  

## 5. 卷积神经网络  
卷积神经网络（CNN）是一类强大的、为处理图像数据而设计的神经网络  
基于卷积神经网络架构的模型在计算机视觉领域中已经占主导地位，当今几乎所有的图像识别、目标检测或语义分割相关的学术竞赛和商业应用都以这种方法为基础  

### 5.1 从全连接层到卷积  
之前讨论的多层感知机十分适合处理表格数据，其中行对应样本，列对应特征  
然而对于高维感知数据，这种缺少结构的网络可能会变得不实用  
#### 5.1.1 不变性  
原理总结 ：  

* **平移不变性** ：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”  
* **局部性** ：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则  

#### 5.1.2 多层感知机的限制  
多层感知机的输入是二维图像 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
</math> ，其隐藏表示 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
</math> 在数学上是一个矩阵，在代码中表示为二维张量  

使用 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
</math> 分别表示输入图像和隐藏表示中位置（i , j）处的像素  

为了使每个隐藏神经元都能接收到每个输入像素的信息，将参数从权重矩阵替换为四阶权重张量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">W</mi>
  </mrow>
</math>  

假设 **U** 包含偏执参数  
全连接层可以形式化地表示为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <msub>
                <mrow data-mjx-texclass="INNER">
                  <mo data-mjx-texclass="OPEN">[</mo>
                  <mrow data-mjx-texclass="ORD">
                    <mi mathvariant="bold">H</mi>
                  </mrow>
                  <mo data-mjx-texclass="CLOSE">]</mo>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>i</mi>
                  <mo>,</mo>
                  <mi>j</mi>
                </mrow>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mo stretchy="false">[</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">U</mi>
              </mrow>
              <msub>
                <mo stretchy="false">]</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>i</mi>
                  <mo>,</mo>
                  <mi>j</mi>
                </mrow>
              </msub>
              <mo>+</mo>
              <munder>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mi>k</mi>
              </munder>
              <munder>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mi>l</mi>
              </munder>
              <mo stretchy="false">[</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="sans-serif">W</mi>
              </mrow>
              <msub>
                <mo stretchy="false">]</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>i</mi>
                  <mo>,</mo>
                  <mi>j</mi>
                  <mo>,</mo>
                  <mi>k</mi>
                  <mo>,</mo>
                  <mi>l</mi>
                </mrow>
              </msub>
              <mo stretchy="false">[</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">X</mi>
              </mrow>
              <msub>
                <mo stretchy="false">]</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>k</mi>
                  <mo>,</mo>
                  <mi>l</mi>
                </mrow>
              </msub>
            </mtd>
          </mtr>
          <mtr>
            <mtd></mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mo stretchy="false">[</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">U</mi>
              </mrow>
              <msub>
                <mo stretchy="false">]</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>i</mi>
                  <mo>,</mo>
                  <mi>j</mi>
                </mrow>
              </msub>
              <mo>+</mo>
              <munder>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mi>a</mi>
              </munder>
              <munder>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mi>b</mi>
              </munder>
              <mo stretchy="false">[</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="sans-serif">V</mi>
              </mrow>
              <msub>
                <mo stretchy="false">]</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>i</mi>
                  <mo>,</mo>
                  <mi>j</mi>
                  <mo>,</mo>
                  <mi>a</mi>
                  <mo>,</mo>
                  <mi>b</mi>
                </mrow>
              </msub>
              <mo stretchy="false">[</mo>
              <mrow data-mjx-texclass="ORD">
                <mi mathvariant="bold">X</mi>
              </mrow>
              <msub>
                <mo stretchy="false">]</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>i</mi>
                  <mo>+</mo>
                  <mi>a</mi>
                  <mo>,</mo>
                  <mi>j</mi>
                  <mo>+</mo>
                  <mi>b</mi>
                </mrow>
              </msub>
              <mo>.</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

从 **W** 到 **V** 的转换只是形式上的转换，因为在这两个四阶张量的元素之间存在一一对应的关系  
只需重新索引下标 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <mi>k</mi>
  <mo>,</mo>
  <mi>l</mi>
  <mo stretchy="false">)</mo>
</math> ，使 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>k</mi>
  <mo>=</mo>
  <mi>i</mi>
  <mo>+</mo>
  <mi>a</mi>
</math> 、<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>l</mi>
  <mo>=</mo>
  <mi>j</mi>
  <mo>+</mo>
  <mi>b</mi>
</math> ，由此可得 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>,</mo>
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">W</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>,</mo>
      <mi>i</mi>
      <mo>+</mo>
      <mi>a</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>+</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</math>  

索引 **a** 和 **b** 通过在正偏移和负偏移之间移动覆盖了整个图像  

对于隐藏表示中任意给定位置（i , j）处的像素值 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
</math> ，可以通过在 x 中以 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo>,</mo>
  <mi>j</mi>
  <mo stretchy="false">)</mo>
</math> 为中心对像素进行加权求和得到，加权使用的权重为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>,</mo>
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</math>  

##### 5.1.2.1 平移不变性  
意味着检测对象在输入 **X** 中的平移，应该仅导致隐藏表示中 **H** 的平移  
**V** 和 **U** 实际上也不依赖 (i , j) 的值，即 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>,</mo>
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</math>  

**U** 仅为常数，如 u  
简化 **H** 为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mi>u</mi>
  <mo>+</mo>
  <munder>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mi>a</mi>
  </munder>
  <munder>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mi>b</mi>
  </munder>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>+</mo>
      <mi>a</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>+</mo>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo>.</mo>
</math>  

这就是 *卷积*  
是在使用系数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
</math> 对位置 (i , j) 附近的像素 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo>+</mo>
  <mi>a</mi>
  <mo>,</mo>
  <mi>j</mi>
  <mo>+</mo>
  <mi>b</mi>
  <mo stretchy="false">)</mo>
</math> 进行加权得到 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
</math>  

##### 5.1.2.2 局部性  
为了收集用来训练参数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
</math> 的相关信息，不应偏离到距 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo>,</mo>
  <mi>j</mi>
  <mo stretchy="false">)</mo>
</math> 很远的地方  
这意味着在 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">|</mo>
  <mi>a</mi>
  <mrow data-mjx-texclass="ORD">
    <mo stretchy="false">|</mo>
  </mrow>
  <mo>&gt;</mo>
  <mi mathvariant="normal">&#x394;</mi>
</math> 或 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">|</mo>
  <mi>b</mi>
  <mrow data-mjx-texclass="ORD">
    <mo stretchy="false">|</mo>
  </mrow>
  <mo>&gt;</mo>
  <mi mathvariant="normal">&#x394;</mi>
</math> 的范围之外，我们可以设置 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mn>0</mn>
</math>   

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <mi>u</mi>
  <mo>+</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>=</mo>
      <mo>&#x2212;</mo>
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
  </munderover>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>b</mi>
      <mo>=</mo>
      <mo>&#x2212;</mo>
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
  </munderover>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>+</mo>
      <mi>a</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>+</mo>
      <mi>b</mi>
    </mrow>
  </msub>
  <mo>.</mo>
</math>  

这便是一个 *卷积层*  
卷积神经网络是包含卷积层的一类特殊的神经网络  
**V** 被称为 *卷积核* 或滤波器 ，或者也可以简单被称为该卷积核的权重  

#### 5.1.3 卷积  
在数学中，两个函数（比如 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>f</mi>
  <mo>,</mo>
  <mi>g</mi>
  <mo>:</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>d</mi>
  </msup>
  <mo accent="false" stretchy="false">&#x2192;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="double-struck">R</mi>
  </mrow>
</math> ）之间的“卷积”被定义为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mo stretchy="false">(</mo>
  <mi>f</mi>
  <mo>&#x2217;</mo>
  <mi>g</mi>
  <mo stretchy="false">)</mo>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mo data-mjx-texclass="OP">&#x222B;</mo>
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">z</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mi>g</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo>&#x2212;</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">z</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mi>d</mi>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">z</mi>
  </mrow>
  <mo>.</mo>
</math>  

卷积是当把一个函数“翻转”并移位 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
</math> 时，测量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>f</mi>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>g</mi>
</math> 之间的重叠  
当为离散对象时，积分变成求和  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mo stretchy="false">(</mo>
  <mi>f</mi>
  <mo>&#x2217;</mo>
  <mi>g</mi>
  <mo stretchy="false">)</mo>
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munder>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mi>a</mi>
  </munder>
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mi>a</mi>
  <mo stretchy="false">)</mo>
  <mi>g</mi>
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo>&#x2212;</mo>
  <mi>a</mi>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

对于二维张量，则为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>f</mi>
</math> 的索引 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <mi>a</mi>
  <mo>,</mo>
  <mi>b</mi>
  <mo stretchy="false">)</mo>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>g</mi>
</math> 的索引 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo>&#x2212;</mo>
  <mi>a</mi>
  <mo>,</mo>
  <mi>j</mi>
  <mo>&#x2212;</mo>
  <mi>b</mi>
  <mo stretchy="false">)</mo>
</math> 上的对应加和  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mo stretchy="false">(</mo>
  <mi>f</mi>
  <mo>&#x2217;</mo>
  <mi>g</mi>
  <mo stretchy="false">)</mo>
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo>,</mo>
  <mi>j</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munder>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mi>a</mi>
  </munder>
  <munder>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mi>b</mi>
  </munder>
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mi>a</mi>
  <mo>,</mo>
  <mi>b</mi>
  <mo stretchy="false">)</mo>
  <mi>g</mi>
  <mo stretchy="false">(</mo>
  <mi>i</mi>
  <mo>&#x2212;</mo>
  <mi>a</mi>
  <mo>,</mo>
  <mi>j</mi>
  <mo>&#x2212;</mo>
  <mi>b</mi>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

#### 5.1.4 通道  
图像一般包含三个通道/三种原色（红色、绿色和蓝色）  
图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，比如包含 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>1024</mn>
  <mo>&#xD7;</mo>
  <mn>1024</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
</math> 个像素  

将 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">X</mi>
  </mrow>
</math> 索引为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">X</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>,</mo>
      <mi>k</mi>
    </mrow>
  </msub>
</math> 由此卷积相应地调整为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
      <mo>,</mo>
      <mi>c</mi>
    </mrow>
  </msub>
</math>  

为了支持输入 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">X</mi>
  </mrow>
</math> 和隐藏表示 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">H</mi>
  </mrow>
</math> 中的多个通道，可以在 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">V</mi>
  </mrow>
</math> 中添加第四个坐标，即 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
      <mo>,</mo>
      <mi>c</mi>
      <mo>,</mo>
      <mi>d</mi>
    </mrow>
  </msub>
</math>

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">H</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>,</mo>
      <mi>d</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>=</mo>
      <mo>&#x2212;</mo>
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
  </munderover>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>b</mi>
      <mo>=</mo>
      <mo>&#x2212;</mo>
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="normal">&#x394;</mi>
    </mrow>
  </munderover>
  <munder>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mi>c</mi>
  </munder>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">V</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>a</mi>
      <mo>,</mo>
      <mi>b</mi>
      <mo>,</mo>
      <mi>c</mi>
      <mo>,</mo>
      <mi>d</mi>
    </mrow>
  </msub>
  <mo stretchy="false">[</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="sans-serif">X</mi>
  </mrow>
  <msub>
    <mo stretchy="false">]</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>+</mo>
      <mi>a</mi>
      <mo>,</mo>
      <mi>j</mi>
      <mo>+</mo>
      <mi>b</mi>
      <mo>,</mo>
      <mi>c</mi>
    </mrow>
  </msub>
  <mo>,</mo>
</math>  

### 5.2 图像卷积  
#### 5.2.1 互相关运算  
严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是互相关运算  
暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示  

输入是高度为3、宽度为3的二维张量  
卷积核的高度和宽度都是2  

![图片](https://zh.d2l.ai/_images/correlation.svg)  

阴影部分是第一个输出元素，以及用于计算输出的输入张量元素和核张量元素  

<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>0</mn>
  <mo>&#xD7;</mo>
  <mn>0</mn>
  <mo>+</mo>
  <mn>1</mn>
  <mo>&#xD7;</mo>
  <mn>1</mn>
  <mo>+</mo>
  <mn>3</mn>
  <mo>&#xD7;</mo>
  <mn>2</mn>
  <mo>+</mo>
  <mn>4</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
  <mo>=</mo>
  <mn>19</mn>
</math>  

在corr2d函数中实现如上过程，该函数接受输入张量X和卷积核张量K，并返回输出张量Y  

```python 
import torch
from torch import nn
from d2l import torch as d2l

def corr2d(X, K):  #@save
    """计算二维互相关运算"""
    h, w = K.shape
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y
```  
#### 5.2.2 卷积层  
基于上面定义的corr2d函数实现二维卷积层  
在__init__构造函数中，将weight和bias声明为两个模型参数  
```python 
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```  
#### 5.2.3 图像中目标的边缘检测  
卷积层的一个简单应用：通过找到像素变化的位置，来检测图像中不同颜色的边缘  
设黑色为0，白色为1  
```python
X = torch.ones((6, 8))
X[:, 2:6] = 0
X
```  
再创造一个卷积核  
```python
K = torch.tensor([[1.0, -1.0]])
``` 
#### 5.2.4 学习卷积核  
```python
# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)

# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
# 其中批量大小和通道数都为1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
lr = 3e-2  # 学习率

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    # 迭代卷积核
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'epoch {i+1}, loss {l.sum():.3f}')
```  
```python
epoch 2, loss 6.422
epoch 4, loss 1.225
epoch 6, loss 0.266
epoch 8, loss 0.070
epoch 10, loss 0.022
```  

#### 5.2.5 互相关和卷积  
值得注意的是，由于卷积核是从数据中学习到的，因此无论这些层执行严格的卷积运算还是互相关运算，卷积层的输出都不会受到影响  
为了与深度学习文献中的标准术语保持一致，将继续把“互相关运算”称为卷积运算  
### 5.3 填充与步幅  
当原始图像边界丢失了许多重要信息，填充就是十分重要的方法  
希望有效降低图像的高度与宽度，调整步幅就十分有效  

#### 5.3.1 填充  
在应用多层卷积时，常常丢失边缘像素  
解决这个问题的简单方法即为填充 ：在输入图像的边界填充元素（通常填充元素是0）  

![图片](https://zh.d2l.ai/_images/conv-pad.svg)  
#### 5.3.2 步幅  
在前面的例子中，默认每次滑动一个元素  
为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素  

将每次滑动元素的数量称为步幅(也称步长)  

![图片](https://zh.d2l.ai/_images/conv-stride.svg)  

### 5.4 多输入多输出通道  
#### 5.4.1 多输入通道  
当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算  
在图中，演示了一个具有两个输入通道的二维互相关运算的示例  

![图片](https://zh.d2l.ai/_images/conv-multi-in.svg)  
#### 5.4.2 多输出通道  
随着神经网络层数的加深，常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度  
可以将每个通道看作对不同特征的响应  
现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的  

```python
def corr2d_multi_in_out(X, K):
    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。
    # 最后将所有结果都叠加在一起
    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)
```  
通过将核张量K与K+1（K中每个元素加）和K+2连接起来，构造了一个具有个输出通道的卷积核
```python
K = torch.stack((K, K + 1, K + 2), 0)
K.shape
```  

### 5.5 汇聚层  
本节将介绍汇聚层，它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性  
#### 5.5.1 最大汇聚层与平均汇聚层  
与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口（有时称为汇聚窗口）遍历的每个位置计算一个输出  

池运算是确定性的，通常计算汇聚窗口中所有元素的最大值或平均值  
这些操作分别称为最大汇聚层和平均汇聚层  

#### 5.5.2 填充和步幅  
与卷积层一样，汇聚层也可以改变输出形状  
和以前一样，可以通过填充和步幅以获得所需的输出形状  
#### 5.5.3 多个通道  
在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总  
这意味着汇聚层的输出通道数与输入通道数相同  

### 5.6 卷积神经网络(LeNet)  
#### 5.6.1 LeNet  
有两个部分构成  

* 卷积编码器：由两个卷积层组成  
* 全连接层密集块：由三个全连接层组成  

![图片](https://zh.d2l.ai/_images/lenet.svg)  
每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层  
这些层将输入映射到多个二维特征输出，通常同时增加通道的数量  
第一卷积层有6个输出通道，而第二个卷积层有16个输出通道  

## 6. 现代卷积神经网络  
这些模型包括 ：  

* AlexNet ：它是第一个在大规模视觉竞赛中击败传统计算机视觉模型的大型神经网络  
* 使用重复块的网络（VGG） ：它利用许多重复的神经网络块  
* 网络中的网络（NiN）:它重复使用由卷积层和卷积层（用来代替全连接层）来构建深层网络  
* 含并行连结的网络（GoogLeNet） ：它使用并行连结的网络，通过不同窗口大小的卷积层和最大汇聚层来并行抽取信息  
* 残差网络（ResNet）： 它通过残差块构建跨层的数据通道，是计算机视觉中最流行的体系架构  
* 稠密连接网络（DenseNet） ：它的计算成本很高，但给我们带来了更好的效果  

### 6.1 深度卷积神经网络(AlexNet)  
#### 6.1.1 AlexNet  
首次证明了学习到的特征可以超越手工设计的特征  
AlexNet和LeNet的架构非常相似，如图7.1.2所示  
![图片](https://zh.d2l.ai/_images/alexnet.svg)  

AlexNet和LeNet的设计理念非常相似，但也存在显著差异  

* AlexNet比相对较小的LeNet5要深得多  
* AlexNet使用ReLU而不是sigmoid作为其激活函数  

##### 6.1.1.1 模型设计  
在AlexNet的第一层，卷积窗口的形状是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>11</mn>
  <mo>&#xD7;</mo>
  <mn>11</mn>
</math>  
由于ImageNet中大多数图像的宽和高比MNIST图像的多10倍以上，因此，需要一个更大的卷积窗口来捕获目标  
第二层中的卷积窗口形状被缩减为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>5</mn>
  <mo>&#xD7;</mo>
  <mn>5</mn>
</math> ，然后是<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>3</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
</math>  
在第一层、第二层和第五层卷积层之后，加入窗口形状为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>3</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
</math>、步幅为2的最大汇聚层  
AlexNet的卷积通道数目是LeNet的10倍  


在最后一个卷积层后有两个全连接层，分别有4096个输出  
##### 6.1.1.2 激活函数  
AlexNet将sigmoid激活函数改为更简单的ReLU激活函数  
##### 6.1.1.3 容量控制与预处理  
AlexNet通过暂退法控制全连接层的模型复杂度，而LeNet只使用了权重衰减  
为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色  

### 6.2 使用块的网络(VGG)  
#### 6.2.1 VGG块  
经典卷积神经网络的基本组成部分是下面的这个序列 ：  

* 带填充以保持分辨率的卷积层  
* 非线性激活函数，如ReLU  
* 汇聚层，如最大汇聚层   

在下面的代码中，我们定义了一个名为vgg_block的函数来实现一个VGG块  
```python  
#该函数有三个参数，分别对应于卷积层的数量num_convs、输入通道的数量in_channels 和输出通道的数量out_channels
import torch
from torch import nn
from d2l import torch as d2l


def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(in_channels, out_channels,
                                kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))
    return nn.Sequential(*layers)
```  
#### 6.2.2 VGG网络  
与AlexNet、LeNet一样，VGG网络可以分为两部分：第一部分主要由卷积层和汇聚层组成，第二部分由全连接层组成  
![图片](https://zh.d2l.ai/_images/vgg.svg)  

原始VGG网络有5个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层  
第一个模块有64个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到512  
由于该网络使用8个卷积层和3个全连接层，因此它通常被称为VGG-11  

### 6.3 网络中的网络(NiN)  
#### 6.3.1 NiN 块  
卷积层的输入和输出由四维张量组成，张量的每个轴分别对应样本、通道、高度和宽度  
另外，全连接层的输入和输出通常是分别对应于样本和特征的二维张量  

NiN的想法是在每个像素位置（针对每个高度和宽度）应用一个全连接层  
如果将权重连接到每个空间位置，可以将其视为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>1</mn>
  <mo>&#xD7;</mo>
  <mn>1</mn>
</math> 卷积层，或作为在每个像素位置上独立作用的全连接层   

从另一个角度看，即将空间维度中的每个像素视为单个样本，将通道维度视为不同特征  
图说明了VGG和NiN及它们的块之间的主要差异  
![图片](https://zh.d2l.ai/_images/nin.svg)  

#### 6.3.2 NiN 模型  
NiN使用窗口形状为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>11</mn>
  <mo>&#xD7;</mo>
  <mn>11</mn>
</math> 、<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>5</mn>
  <mo>&#xD7;</mo>
  <mn>5</mn>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>3</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
</math> 的卷积层，输出通道数量与AlexNet中的相同  
每个NiN块后有一个最大汇聚层，汇聚窗口形状为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>3</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
</math> ，步幅为2  

NiN和AlexNet之间的一个显著区别是NiN完全取消了全连接层  
相反，NiN使用一个NiN块，其输出通道数等于标签类别的数量  
最后放一个全局平均汇聚层，生成一个对数几率  

NiN设计的一个优点是，它显著减少了模型所需参数的数量  
然而，在实践中，这种设计有时会增加训练模型的时间  

### 6.4 含并行连结的网络（GoogLeNet）  
#### 6.4.1 Inception块  
在GoogLeNet中，基本的卷积块被称为Inception块  
![图片](https://zh.d2l.ai/_images/inception.svg)  

Inception块由四条并行路径组成  
前三条路径使用窗口大小为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>1</mn>
  <mo>&#xD7;</mo>
  <mn>1</mn>
</math> 、<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>3</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>5</mn>
  <mo>&#xD7;</mo>
  <mn>5</mn>
</math> 的卷积层，从不同空间大小中提取信息  
 中间的两条路径在输入上执行 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>1</mn>
  <mo>&#xD7;</mo>
  <mn>1</mn>
</math> 卷积，以减少通道数，从而降低模型的复杂性  
第四条路径使用 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>3</mn>
  <mo>&#xD7;</mo>
  <mn>3</mn>
</math> 最大汇聚层，然后使用 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>1</mn>
  <mo>&#xD7;</mo>
  <mn>1</mn>
</math> 卷积层来改变通道数  

```python
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


class Inception(nn.Module):
    # c1--c4是每条路径的输出通道数
    def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):
        super(Inception, self).__init__(**kwargs)
        # 线路1，单1x1卷积层
        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)
        # 线路2，1x1卷积层后接3x3卷积层
        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)
        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)
        # 线路3，1x1卷积层后接5x5卷积层
        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)
        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)
        # 线路4，3x3最大汇聚层后接1x1卷积层
        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)

    def forward(self, x):
        p1 = F.relu(self.p1_1(x))
        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
        p4 = F.relu(self.p4_2(self.p4_1(x)))
        # 在通道维度上连结输出
        return torch.cat((p1, p2, p3, p4), dim=1)
```  

#### 6.4.2 GoogLeNet模型  
GoogLeNet一共使用9个Inception块和全局平均汇聚层的堆叠来生成其估计值  
Inception块之间的最大汇聚层可降低维度  
![图片](https://zh.d2l.ai/_images/inception-full.svg)  

### 6.5 残差网络（ResNet）  
#### 6.5.1 残差块  
![图片](https://zh.d2l.ai/_images/residual-block.svg)  

残差块的实现如下 ：  
```python
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


class Residual(nn.Module):  #@save
    def __init__(self, input_channels, num_channels,
                 use_1x1conv=False, strides=1):
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, num_channels,
                               kernel_size=3, padding=1, stride=strides)
        self.conv2 = nn.Conv2d(num_channels, num_channels,
                               kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2d(input_channels, num_channels,
                                   kernel_size=1, stride=strides)
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm2d(num_channels)
        self.bn2 = nn.BatchNorm2d(num_channels)

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return F.relu(Y)
```  
#### 6.5.2  ResNet模型  
![图片](https://zh.d2l.ai/_images/resnet18.svg)  

### 6.6 稠密连接网络（DenseNet）  
#### 6.6.1 从ResNet到DenseNet  
回想一下任意函数的泰勒展开式，它把这个函数分解成越来越高阶的项   

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mn>0</mn>
  <mo stretchy="false">)</mo>
  <mo>+</mo>
  <msup>
    <mi>f</mi>
    <mo data-mjx-alternate="1">&#x2032;</mo>
  </msup>
  <mo stretchy="false">(</mo>
  <mn>0</mn>
  <mo stretchy="false">)</mo>
  <mi>x</mi>
  <mo>+</mo>
  <mfrac>
    <mrow>
      <msup>
        <mi>f</mi>
        <mo data-mjx-alternate="1">&#x2033;</mo>
      </msup>
      <mo stretchy="false">(</mo>
      <mn>0</mn>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mn>2</mn>
      <mo>!</mo>
    </mrow>
  </mfrac>
  <msup>
    <mi>x</mi>
    <mn>2</mn>
  </msup>
  <mo>+</mo>
  <mfrac>
    <mrow>
      <msup>
        <mi>f</mi>
        <mo data-mjx-alternate="1">&#x2034;</mo>
      </msup>
      <mo stretchy="false">(</mo>
      <mn>0</mn>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mn>3</mn>
      <mo>!</mo>
    </mrow>
  </mfrac>
  <msup>
    <mi>x</mi>
    <mn>3</mn>
  </msup>
  <mo>+</mo>
  <mo>&#x2026;</mo>
  <mo>.</mo>
</math>  

同样，ResNet将函数展开为  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo>+</mo>
  <mi>g</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">x</mi>
  </mrow>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

分为了一个简单的线性项和一个复杂的线性项  
![图片](https://zh.d2l.ai/_images/densenet-block.svg)  

ResNet和DenseNet的关键区别在于，DenseNet输出是连接  
而不是如ResNet的简单相加  

DenseNet这个名字由变量之间的“稠密连接”而得来，最后一层与之前的所有层紧密相连  
![图片](https://zh.d2l.ai/_images/densenet.svg)  

#### 6.6.2 稠密块体  
```python
import torch
from torch import nn
from d2l import torch as d2l


def conv_block(input_channels, num_channels):
    return nn.Sequential(
        nn.BatchNorm2d(input_channels), nn.ReLU(),
        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))
```  
一个稠密块由多个卷积块组成，每个卷积块使用相同数量的输出通道  

在前向传播中，我们将每个卷积块的输入和输出在通道维上连结  
```python
class DenseBlock(nn.Module):
    def __init__(self, num_convs, input_channels, num_channels):
        super(DenseBlock, self).__init__()
        layer = []
        for i in range(num_convs):
            layer.append(conv_block(
                num_channels * i + input_channels, num_channels))
        self.net = nn.Sequential(*layer)

    def forward(self, X):
        for blk in self.net:
            Y = blk(X)
            # 连接通道维度上每个块的输入和输出
            X = torch.cat((X, Y), dim=1)
        return X
```  
#### 6.6.3 过渡层  
```python
def transition_block(input_channels, num_channels):
    return nn.Sequential(
        nn.BatchNorm2d(input_channels), nn.ReLU(),
        nn.Conv2d(input_channels, num_channels, kernel_size=1),
        nn.AvgPool2d(kernel_size=2, stride=2))
```  
#### 6.6.4  DenseNet模型  
DenseNet首先使用同ResNet一样的单卷积层和最大汇聚层  
```python
b1 = nn.Sequential(
    nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
    nn.BatchNorm2d(64), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```  
DenseNet使用的是4个稠密块  
 稠密块里的卷积层通道数（即增长率）设为32，所以每个稠密块将增加128个通道  
```python
# num_channels为当前的通道数
num_channels, growth_rate = 64, 32
num_convs_in_dense_blocks = [4, 4, 4, 4]
blks = []
for i, num_convs in enumerate(num_convs_in_dense_blocks):
    blks.append(DenseBlock(num_convs, num_channels, growth_rate))
    # 上一个稠密块的输出通道数
    num_channels += num_convs * growth_rate
    # 在稠密块之间添加一个转换层，使通道数量减半
    if i != len(num_convs_in_dense_blocks) - 1:
        blks.append(transition_block(num_channels, num_channels // 2))
        num_channels = num_channels // 2
```  
与ResNet类似，最后接上全局汇聚层和全连接层来输出结果  
```python
net = nn.Sequential(
    b1, *blks,
    nn.BatchNorm2d(num_channels), nn.ReLU(),
    nn.AdaptiveAvgPool2d((1, 1)),
    nn.Flatten(),
    nn.Linear(num_channels, 10))
```  

## 7. 循环神经网络  
### 7.1 序列模型  
#### 7.1.1 统计工具  
##### 7.1.1.1 自回归模型  
![](https://zh.d2l.ai/_images/sequence-model.svg)  

整个序列的估计值都将通过以下的方式获得 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x220F;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>T</mi>
  </munderover>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

##### 7.1.1.2 马尔可夫模型  
在自回归模型的近似法中， 使用 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mi>&#x3C4;</mi>
    </mrow>
  </msub>
</math> 而不是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
</math> 来估计 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
</math>   
 只要这种是近似精确的，就说序列满足马尔可夫条件  
特别是，如果 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3C4;</mi>
  <mo>=</mo>
  <mn>1</mn>
</math> ，得到一个一阶马尔可夫模型  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x220F;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>T</mi>
  </munderover>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo stretchy="false">)</mo>
  <mtext>&#xA0;&#x5F53;&#xA0;</mtext>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mn>0</mn>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

当假设 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
</math> 仅是离散值时，这样的模型特别棒， 因为在这种情况下，使用动态规划可以沿着马尔可夫链精确地计算结果  

可以高效地计算<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>+</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo stretchy="false">)</mo>
</math> ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>+</mo>
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>&#x2212;</mo>
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <munder>
                    <mo data-mjx-texclass="OP">&#x2211;</mo>
                    <mrow data-mjx-texclass="ORD">
                      <msub>
                        <mi>x</mi>
                        <mi>t</mi>
                      </msub>
                    </mrow>
                  </munder>
                  <mi>P</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>+</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>t</mi>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>P</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </mtd>
          </mtr>
          <mtr>
            <mtd></mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <munder>
                    <mo data-mjx-texclass="OP">&#x2211;</mo>
                    <mrow data-mjx-texclass="ORD">
                      <msub>
                        <mi>x</mi>
                        <mi>t</mi>
                      </msub>
                    </mrow>
                  </munder>
                  <mi>P</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>+</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo>&#x2223;</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>t</mi>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo stretchy="false">)</mo>
                  <mi>P</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mi>t</mi>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>P</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </mtd>
          </mtr>
          <mtr>
            <mtd></mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <munder>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <msub>
                    <mi>x</mi>
                    <mi>t</mi>
                  </msub>
                </mrow>
              </munder>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>+</mo>
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mi>t</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mi>t</mi>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>&#x2212;</mo>
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

##### 7.1.1.3 因果关系  
基于条件概率公式，我们总是可以写出 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x220F;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mi>T</mi>
    </mrow>
    <mn>1</mn>
  </munderover>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>+</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

### 7.2 语言模型与数据集  
假设长度为 *T* 的文本序列中的词元依次为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>2</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
</math>  
<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
</math>（<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>1</mn>
  <mo>&#x2264;</mo>
  <mi>t</mi>
  <mo>&#x2264;</mo>
  <mi>T</mi>
</math>） 可以被认为是文本序列在时间 t 步处的观测或标签    

在给定这样的文本序列时，语言模型（language model）的目标是估计序列的联合概率  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>2</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

#### 7.3.1 学习语言模型  
从基本概率规则开始 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>2</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x220F;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>T</mi>
  </munderover>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

为了训练语言模型，需要计算单词的概率，以及给定前面几个单词后出现某个单词的条件概率  
这些概率本质上就是语言模型的参数  

一种方法是统计单词“deep”在数据集中的出现次数， 然后将其除以整个语料库中的单词总数  
可以尝试估计  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mover>
      <mi>P</mi>
      <mo stretchy="false">^</mo>
    </mover>
  </mrow>
  <mo stretchy="false">(</mo>
  <mtext>learning</mtext>
  <mo>&#x2223;</mo>
  <mtext>deep</mtext>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>n</mi>
      <mo stretchy="false">(</mo>
      <mtext>deep, learning</mtext>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mi>n</mi>
      <mo stretchy="false">(</mo>
      <mtext>deep</mtext>
      <mo stretchy="false">)</mo>
    </mrow>
  </mfrac>
  <mo>,</mo>
</math>  

#### 7.3.2 马尔可夫模型与n元语法  
如果 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>+</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>+</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo stretchy="false">)</mo>
</math> ， 则序列上的分布满足一阶马尔可夫性质  
阶数越高，对应的依赖关系就越长  
这种性质推导出了许多可以应用于序列建模的近似公式 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <mo stretchy="false">)</mo>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <mo stretchy="false">)</mo>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <mo stretchy="false">)</mo>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mn>1</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mn>4</mn>
              </msub>
              <mo>&#x2223;</mo>
              <msub>
                <mi>x</mi>
                <mn>2</mn>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mn>3</mn>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>.</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  


#### 7.3.3 自然语言统计  
打印词频最高的词
```python  
import random
import torch
from d2l import torch as d2l

tokens = d2l.tokenize(d2l.read_time_machine())
# 因为每个文本行不一定是一个句子或一个段落，因此我们把所有文本行拼接到一起
corpus = [token for line in tokens for token in line]
vocab = d2l.Vocab(corpus)
vocab.token_freqs[:10]
```  
```python
[('the', 2261),
 ('i', 1267),
 ('and', 1245),
 ('of', 1155),
 ('a', 816),
 ('to', 695),
 ('was', 552),
 ('in', 541),
 ('that', 443),
 ('my', 440)]
 ```  

最流行的词看起来很无聊， 这些词通常被称为停用词（stop words），因此可以被过滤掉  

还有个明显的问题是词频衰减的速度相当地快  
![图片](https://zh.d2l.ai/_images/output_language-models-and-dataset_789d14_21_0.svg)  

这意味着单词的频率满足齐普夫定律， 即第 i 个最常用单词的频率 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>n</mi>
    <mi>i</mi>
  </msub>
</math> 为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mi>n</mi>
    <mi>i</mi>
  </msub>
  <mo>&#x221D;</mo>
  <mfrac>
    <mn>1</mn>
    <msup>
      <mi>i</mi>
      <mi>&#x3B1;</mi>
    </msup>
  </mfrac>
  <mo>,</mo>
</math>  

等价于 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>log</mi>
  <mo data-mjx-texclass="NONE">&#x2061;</mo>
  <msub>
    <mi>n</mi>
    <mi>i</mi>
  </msub>
  <mo>=</mo>
  <mo>&#x2212;</mo>
  <mi>&#x3B1;</mi>
  <mi>log</mi>
  <mo data-mjx-texclass="NONE">&#x2061;</mo>
  <mi>i</mi>
  <mo>+</mo>
  <mi>c</mi>
  <mo>,</mo>
</math>  

 这告诉我们想要通过计数统计和平滑来建模单词是不可行的， 因为这样建模的结果会大大高估尾部单词的频率，也就是所谓的不常用单词  

#### 7.3.4 读取长序列数据  
将使用神经网络来训练语言模型， 模型中的网络一次处理具有预定义长度的一个小批量序列  

可以从随机偏移量开始划分序列， 以同时获得覆盖性和随机性  
##### 7.3.4.1 随机采样  
在随机采样中，每个样本都是在原始的长序列上任意捕获的子序列  
在迭代过程中，来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻  
目标是基于到目前为止看到的词元来预测下一个词元， 因此标签是移位了一个词元的原始序列  

下面的代码每次可以从数据中随机生成一个小批量  
参数batch_size指定了每个小批量中子序列样本的数目  
参数num_steps是每个子序列中预定义的时间步数  

```python
def seq_data_iter_random(corpus, batch_size, num_steps):  #@save
    """使用随机抽样生成一个小批量子序列"""
    # 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1
    corpus = corpus[random.randint(0, num_steps - 1):]
    # 减去1，是因为我们需要考虑标签
    num_subseqs = (len(corpus) - 1) // num_steps
    # 长度为num_steps的子序列的起始索引
    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))
    # 在随机抽样的迭代过程中，
    # 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻
    random.shuffle(initial_indices)

    def data(pos):
        # 返回从pos位置开始的长度为num_steps的序列
        return corpus[pos: pos + num_steps]

    num_batches = num_subseqs // batch_size
    for i in range(0, batch_size * num_batches, batch_size):
        # 在这里，initial_indices包含子序列的随机起始索引
        initial_indices_per_batch = initial_indices[i: i + batch_size]
        X = [data(j) for j in initial_indices_per_batch]
        Y = [data(j + 1) for j in initial_indices_per_batch]
        yield torch.tensor(X), torch.tensor(Y)
```  

##### 7.3.4.2 顺序分区  
在迭代过程中，除了对原始序列可以随机抽样外， 还可以保证两个相邻的小批量中的子序列在原始序列上也是相邻的  
```python
def seq_data_iter_sequential(corpus, batch_size, num_steps):  #@save
    """使用顺序分区生成一个小批量子序列"""
    # 从随机偏移量开始划分序列
    offset = random.randint(0, num_steps)
    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size
    Xs = torch.tensor(corpus[offset: offset + num_tokens])
    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])
    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)
    num_batches = Xs.shape[1] // num_steps
    for i in range(0, num_steps * num_batches, num_steps):
        X = Xs[:, i: i + num_steps]
        Y = Ys[:, i: i + num_steps]
        yield X, Y
```  

基于相同的设置，通过顺序分区读取每个小批量的子序列的特征X和标签Y  
```python  
for X, Y in seq_data_iter_sequential(my_seq, batch_size=2, num_steps=5):
    print('X: ', X, '\nY:', Y)
```
将上面的两个采样函数包装到一个类中， 以便稍后可以将其用作数据迭代器  
```python
class SeqDataLoader:  #@save
    """加载序列数据的迭代器"""
    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):
        if use_random_iter:
            self.data_iter_fn = d2l.seq_data_iter_random
        else:
            self.data_iter_fn = d2l.seq_data_iter_sequential
        self.corpus, self.vocab = d2l.load_corpus_time_machine(max_tokens)
        self.batch_size, self.num_steps = batch_size, num_steps

    def __iter__(self):
        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)
```  
定义了一个函数load_data_time_machine， 它同时返回数据迭代器和词表， 因此可以与其他带有load_data前缀的函数类似地使用  
```python
def load_data_time_machine(batch_size, num_steps,  #@save
                           use_random_iter=False, max_tokens=10000):
    """返回时光机器数据集的迭代器和词表"""
    data_iter = SeqDataLoader(
        batch_size, num_steps, use_random_iter, max_tokens)
    return data_iter, data_iter.vocab
```  

### 7.4 循环神经网络  
隐变量模型 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>&#x2248;</mo>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>,</mo>
</math>  

其中 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
</math> 是隐状态， 也称为隐藏变量， 它存储了到时间步 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>t</mi>
  <mo>&#x2212;</mo>
  <mn>1</mn>
</math> 的序列信息  
基于当前输入 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
</math> 和先前隐状态 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
</math> 来计算时间步 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>t</mi>
</math> 处的任何时间的隐状态 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mi>h</mi>
    <mi>t</mi>
  </msub>
  <mo>=</mo>
  <mi>f</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

#### 7.4.1 无隐状态的神经网络  
设隐藏层的激活函数为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3D5;</mi>
</math> ， 给定一个小批量样本 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>n</mi>
      <mo>&#xD7;</mo>
      <mi>d</mi>
    </mrow>
  </msup>
</math> ， 其中批量大小为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>n</mi>
</math> ，输入维度为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>d</mi>
</math> ， 则隐藏层的输出 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>n</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math>
通过下式计算 ：

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <mo>=</mo>
  <mi>&#x3D5;</mi>
  <mo stretchy="false">(</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">X</mi>
  </mrow>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>x</mi>
      <mi>h</mi>
    </mrow>
  </msub>
  <mo>+</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mi>h</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

拥有的隐藏层权重参数为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>x</mi>
      <mi>h</mi>
    </mrow>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>d</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math> ， 偏置参数为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mi>h</mi>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mn>1</mn>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math> ， 以及隐藏单元的数目为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>h</mi>
</math>  
将隐藏变量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
</math> 用作输出层的输入  
输出层如下 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">O</mi>
  </mrow>
  <mo>=</mo>
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">H</mi>
  </mrow>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>q</mi>
    </mrow>
  </msub>
  <mo>+</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mi>q</mi>
  </msub>
  <mo>,</mo>
</math>  

<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow data-mjx-texclass="ORD">
    <mi mathvariant="bold">O</mi>
  </mrow>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>n</mi>
      <mo>&#xD7;</mo>
      <mi>q</mi>
    </mrow>
  </msup>
</math> 是输出变量， <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>q</mi>
    </mrow>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mo>&#xD7;</mo>
      <mi>q</mi>
    </mrow>
  </msup>
</math> 是权重参数， <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mi>q</mi>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mn>1</mn>
      <mo>&#xD7;</mo>
      <mi>q</mi>
    </mrow>
  </msup>
</math> 是输出层的偏置参数  

#### 7.4.2 有隐状态的神经网络  
在这里保存了前一个时间步的隐藏变量 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">H</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
</math> ， 并引入了一个新的权重参数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>h</mi>
    </mrow>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math> ， 来描述如何在当前时间步中使用前一个时间步的隐藏变量  
一起计算出 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">H</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <mo>=</mo>
  <mi>&#x3D5;</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">X</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>x</mi>
      <mi>h</mi>
    </mrow>
  </msub>
  <mo>+</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">H</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>h</mi>
    </mrow>
  </msub>
  <mo>+</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">b</mi>
    </mrow>
    <mi>h</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

图例 ：  

![图片](https://zh.d2l.ai/_images/rnn.svg)  

#### 7.4.3 基于循环神经网络的字符级语言模型  
为了简化后续部分的训练，我们考虑使用字符级语言模型， 将文本词元化为字符而不是单词  
![图片](https://zh.d2l.ai/_images/rnn-train.svg)  
在训练过程中，对每个时间步的输出层的输出进行softmax操作， 然后利用交叉熵损失计算模型输出和标签之间的误差  
#### 7.4.4 困惑度  
通过一个序列中所有的 n 个词元的交叉熵损失的平均值来衡量 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mn>1</mn>
    <mi>n</mi>
  </mfrac>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>n</mi>
  </munderover>
  <mo>&#x2212;</mo>
  <mi>log</mi>
  <mo data-mjx-texclass="NONE">&#x2061;</mo>
  <mi>P</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>&#x2223;</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>,</mo>
</math>  

### 7.5 通过时间反向传播  
#### 7.5.1 循环神经网络的梯度分析  
在这个简化模型中，将时间步 t 的隐状态表示为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>h</mi>
    <mi>t</mi>
  </msub>
</math> ， 输入表示为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
</math> ，输出表示为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>o</mi>
    <mi>t</mi>
  </msub>
</math>   

输入和隐状态可以拼接后与隐藏层中的一个权重变量相乘  
分别使用 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>w</mi>
    <mi>h</mi>
  </msub>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>w</mi>
    <mi>o</mi>
  </msub>
</math> 来表示隐藏层和输出层的权重
每个时间步的隐状态和输出可以写为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <msub>
                <mi>h</mi>
                <mi>t</mi>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mi>f</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>x</mi>
                <mi>t</mi>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>h</mi>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>&#x2212;</mo>
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>w</mi>
                <mi>h</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <msub>
                <mi>o</mi>
                <mi>t</mi>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mi>g</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>h</mi>
                <mi>t</mi>
              </msub>
              <mo>,</mo>
              <msub>
                <mi>w</mi>
                <mi>o</mi>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>,</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

其中 f 和 g 分别是隐藏层和输出层的变换  
有一个链 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo fence="false" stretchy="false">{</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>o</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>,</mo>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>o</mi>
    <mi>t</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo fence="false" stretchy="false">}</mo>
</math> ， 它们通过循环计算彼此依赖  
前向传播相当简单，一次一个时间步的遍历三元组 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mi>t</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>h</mi>
    <mi>t</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>o</mi>
    <mi>t</mi>
  </msub>
  <mo stretchy="false">)</mo>
</math> ， 然后通过一个目标函数在所有个时间步内评估输出 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>o</mi>
    <mi>t</mi>
  </msub>
</math> 和对应的标签 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>y</mi>
    <mi>t</mi>
  </msub>
</math> 之间的差异 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>L</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>x</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>x</mi>
    <mi>T</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>y</mi>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mi>y</mi>
    <mi>T</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>w</mi>
    <mi>h</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>w</mi>
    <mi>o</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mfrac>
    <mn>1</mn>
    <mi>T</mi>
  </mfrac>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>T</mi>
  </munderover>
  <mi>l</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mi>y</mi>
    <mi>t</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>o</mi>
    <mi>t</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

对于反向传播，利用链式法则 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>L</mi>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>w</mi>
                    <mi>h</mi>
                  </msub>
                </mrow>
              </mfrac>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mfrac>
                <mn>1</mn>
                <mi>T</mi>
              </mfrac>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>T</mi>
              </munderover>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>l</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>y</mi>
                    <mi>t</mi>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>o</mi>
                    <mi>t</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>w</mi>
                    <mi>h</mi>
                  </msub>
                </mrow>
              </mfrac>
            </mtd>
          </mtr>
          <mtr>
            <mtd></mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mfrac>
                <mn>1</mn>
                <mi>T</mi>
              </mfrac>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>T</mi>
              </munderover>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>l</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>y</mi>
                    <mi>t</mi>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>o</mi>
                    <mi>t</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>o</mi>
                    <mi>t</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>g</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>h</mi>
                    <mi>t</mi>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>w</mi>
                    <mi>o</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>h</mi>
                    <mi>t</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>h</mi>
                    <mi>t</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>w</mi>
                    <mi>h</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mo>.</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

根据递归计算， <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>h</mi>
    <mi>t</mi>
  </msub>
</math> 既依赖于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
</math> 又依赖于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>w</mi>
    <mi>h</mi>
  </msub>
</math> ， 其中 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
</math> 的计算也依赖于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>w</mi>
    <mi>h</mi>
  </msub>
</math> ，由链式法则可得 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>h</mi>
        <mi>t</mi>
      </msub>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>f</mi>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>x</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>h</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
          <mo>&#x2212;</mo>
          <mn>1</mn>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>+</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>f</mi>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>x</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>h</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
          <mo>&#x2212;</mo>
          <mn>1</mn>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>h</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
          <mo>&#x2212;</mo>
          <mn>1</mn>
        </mrow>
      </msub>
    </mrow>
  </mfrac>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>h</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
          <mo>&#x2212;</mo>
          <mn>1</mn>
        </mrow>
      </msub>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>.</mo>
</math>  

为了导出上述梯度，假设有三个序列 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo fence="false" stretchy="false">{</mo>
  <msub>
    <mi>a</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo fence="false" stretchy="false">}</mo>
  <mo>,</mo>
  <mo fence="false" stretchy="false">{</mo>
  <msub>
    <mi>b</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo fence="false" stretchy="false">}</mo>
  <mo>,</mo>
  <mo fence="false" stretchy="false">{</mo>
  <msub>
    <mi>c</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo fence="false" stretchy="false">}</mo>
</math> ， 当 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>t</mi>
  <mo>=</mo>
  <mn>1</mn>
  <mo>,</mo>
  <mn>2</mn>
  <mo>,</mo>
  <mo>&#x2026;</mo>
</math> 时，序列满足 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>a</mi>
    <mrow data-mjx-texclass="ORD">
      <mn>0</mn>
    </mrow>
  </msub>
  <mo>=</mo>
  <mn>0</mn>
</math> 且 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>a</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <msub>
    <mi>b</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo>+</mo>
  <msub>
    <mi>c</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <msub>
    <mi>a</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </msub>
</math>   
对于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>t</mi>
  <mo>&#x2265;</mo>
  <mn>1</mn>
</math> ，可以得到 ：  
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <msub>
    <mi>a</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo>=</mo>
  <msub>
    <mi>b</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
    </mrow>
  </msub>
  <mo>+</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </munderover>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <munderover>
      <mo data-mjx-texclass="OP">&#x220F;</mo>
      <mrow data-mjx-texclass="ORD">
        <mi>j</mi>
        <mo>=</mo>
        <mi>i</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
      <mrow data-mjx-texclass="ORD">
        <mi>t</mi>
      </mrow>
    </munderover>
    <msub>
      <mi>c</mi>
      <mrow data-mjx-texclass="ORD">
        <mi>j</mi>
      </mrow>
    </msub>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <msub>
    <mi>b</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
    </mrow>
  </msub>
  <mo>.</mo>
</math>  

基于下列公式替换 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>a</mi>
    <mi>t</mi>
  </msub>
</math> 、 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>b</mi>
    <mi>t</mi>
  </msub>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>c</mi>
    <mi>t</mi>
  </msub>
</math> ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <msub>
                <mi>a</mi>
                <mi>t</mi>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>h</mi>
                    <mi>t</mi>
                  </msub>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>w</mi>
                    <mi>h</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <msub>
                <mi>b</mi>
                <mi>t</mi>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>f</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                    </mrow>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>h</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>w</mi>
                    <mi>h</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>w</mi>
                    <mi>h</mi>
                  </msub>
                </mrow>
              </mfrac>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <msub>
                <mi>c</mi>
                <mi>t</mi>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>f</mi>
                  <mo stretchy="false">(</mo>
                  <msub>
                    <mi>x</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                    </mrow>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>h</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                  <mo>,</mo>
                  <msub>
                    <mi>w</mi>
                    <mi>h</mi>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mi>h</mi>
                    <mrow data-mjx-texclass="ORD">
                      <mi>t</mi>
                      <mo>&#x2212;</mo>
                      <mn>1</mn>
                    </mrow>
                  </msub>
                </mrow>
              </mfrac>
              <mo>,</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

转化出下面的式子 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>h</mi>
        <mi>t</mi>
      </msub>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>f</mi>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>x</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>h</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
          <mo>&#x2212;</mo>
          <mn>1</mn>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>+</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mn>1</mn>
    </mrow>
  </munderover>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <munderover>
      <mo data-mjx-texclass="OP">&#x220F;</mo>
      <mrow data-mjx-texclass="ORD">
        <mi>j</mi>
        <mo>=</mo>
        <mi>i</mi>
        <mo>+</mo>
        <mn>1</mn>
      </mrow>
      <mrow data-mjx-texclass="ORD">
        <mi>t</mi>
      </mrow>
    </munderover>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow data-mjx-texclass="ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>h</mi>
          <mrow data-mjx-texclass="ORD">
            <mi>j</mi>
            <mo>&#x2212;</mo>
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>w</mi>
          <mi>h</mi>
        </msub>
        <mo stretchy="false">)</mo>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mi>h</mi>
          <mrow data-mjx-texclass="ORD">
            <mi>j</mi>
            <mo>&#x2212;</mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>f</mi>
      <mo stretchy="false">(</mo>
      <msub>
        <mi>x</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>i</mi>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>h</mi>
        <mrow data-mjx-texclass="ORD">
          <mi>i</mi>
          <mo>&#x2212;</mo>
          <mn>1</mn>
        </mrow>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mi>w</mi>
        <mi>h</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>.</mo>
</math>  

虽然可以使用链式法则递归地计算 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <msub>
    <mi>h</mi>
    <mi>t</mi>
  </msub>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <msub>
    <mi>w</mi>
    <mi>h</mi>
  </msub>
</math> ， 但当 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>t</mi>
</math> 很大时这个链就会变得很长  

需要方法来处理这一问题  
##### 7.5.1.1 完全计算  
##### 7.5.1.2 截断时间流  
可以在 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3C4;</mi>
</math> 步后截断中的求和计算
这会带来真实梯度的近似， 只需将求和终止为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <msub>
    <mi>h</mi>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>&#x2212;</mo>
      <mi>&#x3C4;</mi>
    </mrow>
  </msub>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <msub>
    <mi>w</mi>
    <mi>h</mi>
  </msub>
</math>

##### 7.5.1.3 随机截断  
可以用一个随机变量替换 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <msub>
    <mi>h</mi>
    <mi>t</mi>
  </msub>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <msub>
    <mi>w</mi>
    <mi>h</mi>
  </msub>
</math> ， 该随机变量在预期中是正确的，但是会截断序列  

##### 7.5.1.4 比较策略  
![图片](https://zh.d2l.ai/_images/truncated-bptt.svg)  

#### 7.5.2 通过时间反向传播的细节  
为了保持简单，考虑一个没有偏置参数的循环神经网络， 其在隐藏层中的激活函数使用恒等映射（<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3D5;</mi>
  <mo stretchy="false">(</mo>
  <mi>x</mi>
  <mo stretchy="false">)</mo>
  <mo>=</mo>
  <mi>x</mi>
</math>）  

对于时间步 t ，设单个样本的输入及其对应的标签分别为 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">x</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>d</mi>
  </msup>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mi>y</mi>
    <mi>t</mi>
  </msub>
</math>   
计算隐状态 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">h</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>h</mi>
  </msup>
</math> 和输出 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">o</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>q</mi>
  </msup>
</math> 的方式为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">h</mi>
                </mrow>
                <mi>t</mi>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">W</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>h</mi>
                  <mi>x</mi>
                </mrow>
              </msub>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
                <mi>t</mi>
              </msub>
              <mo>+</mo>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">W</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>h</mi>
                  <mi>h</mi>
                </mrow>
              </msub>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">h</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>&#x2212;</mo>
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">o</mi>
                </mrow>
                <mi>t</mi>
              </msub>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">W</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>q</mi>
                  <mi>h</mi>
                </mrow>
              </msub>
              <msub>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">h</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                </mrow>
              </msub>
              <mo>,</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

用 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>l</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">o</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>y</mi>
    <mi>t</mi>
  </msub>
  <mo stretchy="false">)</mo>
</math> 表示时间步 t 处的损失函数， 则的目标函数的总体损失是 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mi>L</mi>
  <mo>=</mo>
  <mfrac>
    <mn>1</mn>
    <mi>T</mi>
  </mfrac>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>T</mi>
  </munderover>
  <mi>l</mi>
  <mo stretchy="false">(</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">o</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <mo>,</mo>
  <msub>
    <mi>y</mi>
    <mi>t</mi>
  </msub>
  <mo stretchy="false">)</mo>
  <mo>.</mo>
</math>  

![图片](https://zh.d2l.ai/_images/rnn-bptt.svg)  

首先，在任意时间步 t ，目标函数关于模型输出的微分计算是相当简单的 ：   

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
        <mi>t</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>l</mi>
      <mo stretchy="false">(</mo>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
        <mi>t</mi>
      </msub>
      <mo>,</mo>
      <msub>
        <mi>y</mi>
        <mi>t</mi>
      </msub>
      <mo stretchy="false">)</mo>
    </mrow>
    <mrow>
      <mi>T</mi>
      <mo>&#x22C5;</mo>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
        <mi>t</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>q</mi>
  </msup>
  <mo>.</mo>
</math>  

可以计算目标函数关于输出层中参数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mi>h</mi>
    </mrow>
  </msub>
</math> 的梯度 ： <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <mi>L</mi>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mi>h</mi>
    </mrow>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mo>&#xD7;</mo>
      <mi>h</mi>
    </mrow>
  </msup>
</math>  
目标函数 **L** 通过 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">o</mi>
    </mrow>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">o</mi>
    </mrow>
    <mi>T</mi>
  </msub>
</math> 依赖于 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mi>h</mi>
    </mrow>
  </msub>
</math>   

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">W</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mi>q</mi>
          <mi>h</mi>
        </mrow>
      </msub>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>T</mi>
  </munderover>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>L</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">o</mi>
          </mrow>
          <mi>t</mi>
        </msub>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">o</mi>
          </mrow>
          <mi>t</mi>
        </msub>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">W</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mi>q</mi>
            <mi>h</mi>
          </mrow>
        </msub>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>t</mi>
      <mo>=</mo>
      <mn>1</mn>
    </mrow>
    <mi>T</mi>
  </munderover>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
        <mi>t</mi>
      </msub>
    </mrow>
  </mfrac>
  <msubsup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">h</mi>
    </mrow>
    <mi>t</mi>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msubsup>
  <mo>,</mo>
</math>  

根据链式法则，隐状态的梯度 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x2202;</mi>
  <mi>L</mi>
  <mrow data-mjx-texclass="ORD">
    <mo>/</mo>
  </mrow>
  <mi>&#x2202;</mi>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">h</mi>
    </mrow>
    <mi>t</mi>
  </msub>
  <mo>&#x2208;</mo>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="double-struck">R</mi>
    </mrow>
    <mi>h</mi>
  </msup>
</math> 在任何时间步骤 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>t</mi>
  <mo>&lt;</mo>
  <mi>T</mi>
</math> 时都可以递归地计算为 ：  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">h</mi>
        </mrow>
        <mi>t</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>L</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">h</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mi>t</mi>
            <mo>+</mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">h</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mi>t</mi>
            <mo>+</mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">h</mi>
          </mrow>
          <mi>t</mi>
        </msub>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>+</mo>
  <mtext>prod</mtext>
  <mrow data-mjx-texclass="INNER">
    <mo data-mjx-texclass="OPEN">(</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <mi>L</mi>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">o</mi>
          </mrow>
          <mi>t</mi>
        </msub>
      </mrow>
    </mfrac>
    <mo>,</mo>
    <mfrac>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">o</mi>
          </mrow>
          <mi>t</mi>
        </msub>
      </mrow>
      <mrow>
        <mi>&#x2202;</mi>
        <msub>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">h</mi>
          </mrow>
          <mi>t</mi>
        </msub>
      </mrow>
    </mfrac>
    <mo data-mjx-texclass="CLOSE">)</mo>
  </mrow>
  <mo>=</mo>
  <msubsup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>h</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msubsup>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">h</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mi>t</mi>
          <mo>+</mo>
          <mn>1</mn>
        </mrow>
      </msub>
    </mrow>
  </mfrac>
  <mo>+</mo>
  <msubsup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mi>h</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msubsup>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
        <mi>t</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>.</mo>
</math>  

为了进行分析，对于任何时间步 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mn>1</mn>
  <mo>&#x2264;</mo>
  <mi>t</mi>
  <mo>&#x2264;</mo>
  <mi>T</mi>
</math> 展开递归计算得  

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">h</mi>
        </mrow>
        <mi>t</mi>
      </msub>
    </mrow>
  </mfrac>
  <mo>=</mo>
  <munderover>
    <mo data-mjx-texclass="OP">&#x2211;</mo>
    <mrow data-mjx-texclass="ORD">
      <mi>i</mi>
      <mo>=</mo>
      <mi>t</mi>
    </mrow>
    <mi>T</mi>
  </munderover>
  <msup>
    <mrow data-mjx-texclass="ORD">
      <mrow data-mjx-texclass="INNER">
        <mo data-mjx-texclass="OPEN">(</mo>
        <msubsup>
          <mrow data-mjx-texclass="ORD">
            <mi mathvariant="bold">W</mi>
          </mrow>
          <mrow data-mjx-texclass="ORD">
            <mi>h</mi>
            <mi>h</mi>
          </mrow>
          <mi mathvariant="normal">&#x22A4;</mi>
        </msubsup>
        <mo data-mjx-texclass="CLOSE">)</mo>
      </mrow>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>T</mi>
      <mo>&#x2212;</mo>
      <mi>i</mi>
    </mrow>
  </msup>
  <msubsup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>q</mi>
      <mi>h</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msubsup>
  <mfrac>
    <mrow>
      <mi>&#x2202;</mi>
      <mi>L</mi>
    </mrow>
    <mrow>
      <mi>&#x2202;</mi>
      <msub>
        <mrow data-mjx-texclass="ORD">
          <mi mathvariant="bold">o</mi>
        </mrow>
        <mrow data-mjx-texclass="ORD">
          <mi>T</mi>
          <mo>+</mo>
          <mi>t</mi>
          <mo>&#x2212;</mo>
          <mi>i</mi>
        </mrow>
      </msub>
    </mrow>
  </mfrac>
  <mo>.</mo>
</math>  

这个简单的线性例子已经展现了长序列模型的一些关键问题： 它陷入到 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msubsup>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>h</mi>
    </mrow>
    <mi mathvariant="normal">&#x22A4;</mi>
  </msubsup>
</math>
的潜在的非常大的幂  

在这个幂中，小于1的特征值将会消失，大于1的特征值将会发散   
这在数值上是不稳定的，表现形式为梯度消失或梯度爆炸  

最后， 图8.7.2表明： 目标函数 **L** 通过隐状态 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">h</mi>
    </mrow>
    <mn>1</mn>
  </msub>
  <mo>,</mo>
  <mo>&#x2026;</mo>
  <mo>,</mo>
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">h</mi>
    </mrow>
    <mi>T</mi>
  </msub>
</math> 依赖于隐藏层中的模型参数 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>x</mi>
    </mrow>
  </msub>
</math>  和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msub>
    <mrow data-mjx-texclass="ORD">
      <mi mathvariant="bold">W</mi>
    </mrow>
    <mrow data-mjx-texclass="ORD">
      <mi>h</mi>
      <mi>h</mi>
    </mrow>
  </msub>
</math>   

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true" columnalign="right" columnspacing="0em" rowspacing="3pt">
    <mtr>
      <mtd>
        <mtable displaystyle="true" columnalign="right left" columnspacing="0em" rowspacing="3pt">
          <mtr>
            <mtd>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>L</mi>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mrow data-mjx-texclass="ORD">
                      <mi mathvariant="bold">W</mi>
                    </mrow>
                    <mrow data-mjx-texclass="ORD">
                      <mi>h</mi>
                      <mi>x</mi>
                    </mrow>
                  </msub>
                </mrow>
              </mfrac>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>T</mi>
              </munderover>
              <mtext>prod</mtext>
              <mrow data-mjx-texclass="INNER">
                <mo data-mjx-texclass="OPEN">(</mo>
                <mfrac>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <mi>L</mi>
                  </mrow>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <msub>
                      <mrow data-mjx-texclass="ORD">
                        <mi mathvariant="bold">h</mi>
                      </mrow>
                      <mi>t</mi>
                    </msub>
                  </mrow>
                </mfrac>
                <mo>,</mo>
                <mfrac>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <msub>
                      <mrow data-mjx-texclass="ORD">
                        <mi mathvariant="bold">h</mi>
                      </mrow>
                      <mi>t</mi>
                    </msub>
                  </mrow>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <msub>
                      <mrow data-mjx-texclass="ORD">
                        <mi mathvariant="bold">W</mi>
                      </mrow>
                      <mrow data-mjx-texclass="ORD">
                        <mi>h</mi>
                        <mi>x</mi>
                      </mrow>
                    </msub>
                  </mrow>
                </mfrac>
                <mo data-mjx-texclass="CLOSE">)</mo>
              </mrow>
              <mo>=</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>T</mi>
              </munderover>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>L</mi>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mrow data-mjx-texclass="ORD">
                      <mi mathvariant="bold">h</mi>
                    </mrow>
                    <mi>t</mi>
                  </msub>
                </mrow>
              </mfrac>
              <msubsup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
                <mi>t</mi>
                <mi mathvariant="normal">&#x22A4;</mi>
              </msubsup>
              <mo>,</mo>
            </mtd>
          </mtr>
          <mtr>
            <mtd>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>L</mi>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mrow data-mjx-texclass="ORD">
                      <mi mathvariant="bold">W</mi>
                    </mrow>
                    <mrow data-mjx-texclass="ORD">
                      <mi>h</mi>
                      <mi>h</mi>
                    </mrow>
                  </msub>
                </mrow>
              </mfrac>
            </mtd>
            <mtd>
              <mi></mi>
              <mo>=</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>T</mi>
              </munderover>
              <mtext>prod</mtext>
              <mrow data-mjx-texclass="INNER">
                <mo data-mjx-texclass="OPEN">(</mo>
                <mfrac>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <mi>L</mi>
                  </mrow>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <msub>
                      <mrow data-mjx-texclass="ORD">
                        <mi mathvariant="bold">h</mi>
                      </mrow>
                      <mi>t</mi>
                    </msub>
                  </mrow>
                </mfrac>
                <mo>,</mo>
                <mfrac>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <msub>
                      <mrow data-mjx-texclass="ORD">
                        <mi mathvariant="bold">h</mi>
                      </mrow>
                      <mi>t</mi>
                    </msub>
                  </mrow>
                  <mrow>
                    <mi>&#x2202;</mi>
                    <msub>
                      <mrow data-mjx-texclass="ORD">
                        <mi mathvariant="bold">W</mi>
                      </mrow>
                      <mrow data-mjx-texclass="ORD">
                        <mi>h</mi>
                        <mi>h</mi>
                      </mrow>
                    </msub>
                  </mrow>
                </mfrac>
                <mo data-mjx-texclass="CLOSE">)</mo>
              </mrow>
              <mo>=</mo>
              <munderover>
                <mo data-mjx-texclass="OP">&#x2211;</mo>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mi>T</mi>
              </munderover>
              <mfrac>
                <mrow>
                  <mi>&#x2202;</mi>
                  <mi>L</mi>
                </mrow>
                <mrow>
                  <mi>&#x2202;</mi>
                  <msub>
                    <mrow data-mjx-texclass="ORD">
                      <mi mathvariant="bold">h</mi>
                    </mrow>
                    <mi>t</mi>
                  </msub>
                </mrow>
              </mfrac>
              <msubsup>
                <mrow data-mjx-texclass="ORD">
                  <mi mathvariant="bold">h</mi>
                </mrow>
                <mrow data-mjx-texclass="ORD">
                  <mi>t</mi>
                  <mo>&#x2212;</mo>
                  <mn>1</mn>
                </mrow>
                <mi mathvariant="normal">&#x22A4;</mi>
              </msubsup>
              <mo>,</mo>
            </mtd>
          </mtr>
        </mtable>
      </mtd>
    </mtr>
  </mtable>
</math>  

